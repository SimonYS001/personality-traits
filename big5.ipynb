{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2443c616-a34b-4b01-9c2a-9c085c5bcae8",
   "metadata": {},
   "source": [
    "# Personality traits\n",
    "\n",
    "This notebook is an implementation of [Tailoring Personality Traits in Large Language Models via Unsupervisedly-built Personalised Lexicons](https://arxiv.org/pdf/2310.16582.pdf). I did not exactly repeat the prompts for the dataset because they were obviously bad and improving them was very low hanging fruit. I added more detail to the descriptions of personality traits, together with system prompts and some output optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a5afd2-ee73-4954-b46e-022bc221f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from typing import Dict, List\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b51231-b0d9-4417-94e5-b21fda9a743f",
   "metadata": {},
   "source": [
    "### Part 1 — construct the data for UBPL\n",
    "\n",
    "The first step is to construct the data required in order to generate the dictionary data for the UBPL. That involves:\n",
    "1. Construct a series of situational judgement test (SJT) scenarios via GPT4\n",
    "2. Use GPT4 under different personality type system prompts to answer those SJTs\n",
    "3. Use GPT4 to score each response against each of the big five personality traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ec2ee3-a803-4bee-803f-4eeef6ba39f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = \"\"\"The following are descriptions of the five personality traits in the Big Five personality theory used to assess a person’s personality:\n",
    "1. Openness: inventive and curious versus dogmatic and cautious.\n",
    "2. Conscientiousness: efficient and organized versus sloppy and careless.\n",
    "3. Extraversion: sociable and energetic versus reserved and solitary.\n",
    "4. Agreeableness: trustworthy, straightforward, generous, and modest versus unreliable, complicated, meager, and boastful.\n",
    "5. Neuroticism: sensitive and nervous versus secure and confident.\n",
    "Now, assuming you are a psychology expert, you must know about situational judgment tests. In situational judgment tests, participants make their own choices or express their \n",
    "opinions after listening to a scene, and then psychologists analyze their personality traits based on their reactions. You will use this method to evaluate the five personality \n",
    "traits of the subjects. To achieve this, you need to design different contextual content. Please construct contextual content (only contextual content, please ensure the diversity \n",
    "and rationality of the contextual content you construct and ensure that the contextual content you construct can be effectively used to evaluate the above five personality traits of \n",
    "the subjects.\n",
    "\n",
    "You should return 10 situational judgement test questions as JSON in the following format. You do not need to return multiple choice answers - just the scenarios\n",
    "ending in a question that would elicit an SJT answer:\n",
    "\n",
    "{ 1: \"SJT scenario\", 2: \"SJT scenario\" }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a4606-f924-4b91-bdac-fe1a9dd4697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa1670-7500-48b5-b9a4-704079267ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b206b84-c634-4c00-b6b8-083f1de1f3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat_completion(\n",
    "  messages: List[Dict],\n",
    "  model: str = 'gpt-4-1106-preview',\n",
    "  temperature: float = 0.8,\n",
    "  response_format: Dict = { \"type\": \"text\" },\n",
    "  stop: List[str] = []\n",
    ") -> str:\n",
    "    try:\n",
    "        response = openai_client.chat.completions.create(messages=messages, model=model, temperature=temperature, response_format=response_format, stop=stop)\n",
    "        if response.choices and len(response.choices) > 0: \n",
    "            return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69394c10-8c60-433b-9dce-837dd65118ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BOO! I can read your message. How can I assist you today?'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chat_completion([{ \"role\": \"user\", \"content\": \"hello this is a test if you can read it shout BOO\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ed7461-171d-4768-8c27-4408c98e6697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9232fd4e-0d91-4115-b1c8-7209adc2c259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': \"You have recently started a new job and are about to attend your first team meeting. The team leader asks everyone to suggest a new project idea. Do you propose an innovative and unconventional project that you've been thinking about, or do you wait to hear the ideas of others first?\", '2': 'You are in charge of organizing a charity event. The tasks include managing volunteers, setting up the event space, and handling finances. Do you create a detailed plan and timeline for all tasks and delegate responsibilities accordingly?', '3': \"At a social gathering, you find yourself surrounded by people you've never met before. Do you strike up a conversation and introduce yourself to as many people as possible, or do you stick to the outskirts of the group and wait for someone to approach you?\", '4': 'A colleague at work confides in you about a personal struggle they are facing. Do you listen and offer your support and assistance, or do you keep the conversation strictly professional and avoid getting involved?', '5': 'During a performance review, your manager criticizes an aspect of your work. Do you take this criticism personally and feel anxious about your job security, or do you view it as constructive feedback to improve your performance?', '6': 'When a friend asks for your opinion on a sensitive topic, do you give an honest and straightforward response, even if it might be hard for them to hear, or do you try to soften your words to avoid any potential conflict?', '7': 'You are leading a project at work with a tight deadline. One team member is not meeting their deliverables, which is putting the project at risk. Do you confront them directly and demand immediate improvement, or do you offer support and ask if there are any obstacles they are facing?', '8': 'You receive an invitation to an event that does not particularly interest you, but attending could mean networking opportunities. Do you go to the event with the intention to meet new people and potentially benefit your career, or do you decline because it does not align with your personal interests?', '9': 'Your friend has been planning an outdoor wedding for months, but the weather forecast predicts heavy rain for the big day. Do you reassure them that everything will work out fine and help to find solutions, or do you focus on the potential issues and suggest they consider a plan B?', '10': 'In a team meeting, a colleague proposes a risky idea that could lead to a significant payoff for the company. Do you support the idea and encourage taking a chance, or do you express concerns and push for a more conservative approach?'}\n"
     ]
    }
   ],
   "source": [
    "test_response = await chat_completion([{ \"role\": \"user\", \"content\": prompt1}], response_format={ \"type\": \"json_object\" })\n",
    "print(json.loads(test_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26cff90-2a91-4a56-872b-1502cb435e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 total scenarios written to file\n",
      "20 total scenarios written to file\n",
      "30 total scenarios written to file\n",
      "40 total scenarios written to file\n",
      "50 total scenarios written to file\n",
      "60 total scenarios written to file\n",
      "70 total scenarios written to file\n",
      "80 total scenarios written to file\n",
      "90 total scenarios written to file\n",
      "100 total scenarios written to file\n",
      "110 total scenarios written to file\n",
      "120 total scenarios written to file\n",
      "130 total scenarios written to file\n",
      "140 total scenarios written to file\n",
      "150 total scenarios written to file\n",
      "170 total scenarios written to file\n",
      "180 total scenarios written to file\n",
      "190 total scenarios written to file\n",
      "200 total scenarios written to file\n",
      "210 total scenarios written to file\n",
      "220 total scenarios written to file\n",
      "230 total scenarios written to file\n",
      "240 total scenarios written to file\n",
      "250 total scenarios written to file\n",
      "260 total scenarios written to file\n",
      "270 total scenarios written to file\n",
      "280 total scenarios written to file\n",
      "290 total scenarios written to file\n",
      "300 total scenarios written to file\n",
      "310 total scenarios written to file\n",
      "320 total scenarios written to file\n",
      "330 total scenarios written to file\n",
      "340 total scenarios written to file\n",
      "350 total scenarios written to file\n",
      "360 total scenarios written to file\n",
      "370 total scenarios written to file\n",
      "380 total scenarios written to file\n",
      "390 total scenarios written to file\n",
      "400 total scenarios written to file\n"
     ]
    }
   ],
   "source": [
    "scenarios = []\n",
    "counter = 0\n",
    "for i in range(40):\n",
    "    response = await chat_completion([{ \"role\": \"user\", \"content\": prompt1}], response_format={ \"type\": \"json_object\" })\n",
    "    json_response = json.loads(response)\n",
    "    vals = json_response.values()\n",
    "    num = len(vals)\n",
    "    scenarios += vals\n",
    "    with open('scenarios_2.txt', 'a') as file:\n",
    "        for s in vals:\n",
    "            file.write(s + '\\n')\n",
    "    counter += num\n",
    "    print(f'{counter} total scenarios written to file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dfbc94-1aae-417d-a86b-935e00854635",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scenarios.txt', 'r') as file:\n",
    "    text = file.readlines()\n",
    "    text = list(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2c85e1-d7f1-4acd-8e77-19301d306b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scenarios_2.txt', 'w') as file:\n",
    "    for t in text:\n",
    "        file.write(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2309306-c5f0-4e0a-873c-121b8e9fc59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdd4d4d-0303-4a9f-90b5-e45645b5979e",
   "metadata": {},
   "source": [
    "Now that we have scenarios, we are going to produce 10 personality profiles based on the 5 personality traits, splitting into high/low buckets on each trait dimension. In each profile, we are going to assume the profile of a single personality trait (low or high on one dimension), and generate responses to all 50 questions that align with that personality trait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df4350-4867-4d17-a610-c190d6befaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_traits = {\n",
    "    \"openness\": {\n",
    "        \"description\": \"Openness (also referred to as openness to experience) emphasizes imagination, curiosity, adventure, insight and variety of experience.\", \n",
    "        \"high\": \"People who are open to experience are intellectually curious, open to emotion, sensitive to beauty, and willing to try new things. They tend to be, when compared to closed people, more creative and more aware of their feelings. They are also more likely to hold unconventional beliefs. However, they may perceived as unpredictable or lacking focus.\", \n",
    "        \"low\": \"Those with low openness want to be fulfilled by persevering and are characterised as pragmatic and data-driven – sometimes even perceived to be dogmatic and closed-minded.\"\n",
    "    },\n",
    "    \"conscientiousness\": {\n",
    "        \"description\": \"Conscientiousness is one defined by high levels of thoughtfulness, diligence, impulse control, and goal-directed behaviors. It implies a desire to do a task well, and to take obligations to others seriously.\", \n",
    "        \"high\": \"Highly conscientious people tend to be organized and mindful of details. They plan ahead, think about how their behavior affects others, and are mindful of deadlines. They tend to be efficient and organised.\", \n",
    "        \"low\": \"People with low conscientiousness tend to be easygoing and disorderly. They may procrastinate to get things done, sometimes missing deadlines completely. They prefer flexibility and spontaneity, but can become sloppy and unreliable.\"\n",
    "    },\n",
    "    \"extraversion\": {\n",
    "        \"description\": \"Extraversion (or extroversion) is a personality trait characterized by excitability, sociability, talkativeness, assertiveness, and emotional expressiveness.\", \n",
    "        \"high\": \"Extroverts (people high in extraversion) are outgoing and tend to gain energy in social situations. Being around others helps them feel energized and excited.  They tend to be enthusiastic and action-oriented. They possess high group visibility, like to talk, and assert themselves. Extraverts may appear more dominant in social settings, as opposed to introverts in that setting.\", \n",
    "        \"low\": \"Introverts (people low in exraversion) tend to be more reserved. They have less energy to expend in social settings and social events can feel draining. Introverts often require a period of solitude and quiet in order to “recharge. They tend to seem quiet, low-key, deliberate, and less involved in the social world.\"\n",
    "    },\n",
    "    \"agreeableness\": {\n",
    "        \"description\": \"Agreeableness includes attributes such as trust, altruism, kindness, affection, and other prosocial behaviors. It is the general concern for social harmony\", \n",
    "        \"high\": \"People who are high in agreeableness value getting along with others. They are generally considerate, kind, generous, trusting and trustworthy, helpful, and willing to compromise their interests with others.\", \n",
    "        \"low\": \"People low in agreeableness place self-interest above getting along with others. They are generally unconcerned with others' well-being and are less likely to extend themselves for other people. This can cause them to be suspicious, unfriendly, and uncooperative.\"\n",
    "    },\n",
    "    \"neuroticism\": {\n",
    "        \"description\": \"Neuroticism is a personality trait characterized by sadness, moodiness, and emotional instability.\", \n",
    "        \"high\": \"People who are high in neuroticism tend to experience mood swings, anxiety, irritability, and sadness. eurotic people are emotionally reactive and vulnerable to stress.\", \n",
    "        \"low\": \"People who are low in neuroticism tend to be calm, emotionally stable, and free from persistent negative feelings\"\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e003d50-c20b-42b3-8323-8092e7d0f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['James', 'Alice', 'Boris', 'Lena', 'Alex', 'Hannah', 'Jeremy', 'Eva', 'Ben', 'Laura']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50225bc5-72a5-4d30-98d9-09d484a12648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt(name:str, personality_trait_name:str, level:str):\n",
    "    personality_trait_info = personality_traits[personality_trait_name]\n",
    "    return f\"\"\"You are {name}. You are characterised by {level} {personality_trait_name}. Your will respond as {name} to every request by fully assuming this characteristic.\n",
    "    \n",
    "    {personality_trait_info['description']}\n",
    "    {personality_trait_info['high']}\n",
    "    {personality_trait_info['low']}\n",
    "    \n",
    "    You will be given a question, and your responsibility is to answer that question adhering to this personality description. Simply answer the question directly as {name} - do not include\n",
    "    any introductory sentence. Remember, you are {name}. You are {level.upper()} {personality_trait_name}.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14ed5de-88ef-45ec-9f4c-2bf144f9bfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are James. You are characterised by low agreeableness. Your will respond as James to every request by fully assuming this characteristic.\n",
      "    \n",
      "    Agreeableness includes attributes such as trust, altruism, kindness, affection, and other prosocial behaviors. It is the general concern for social harmony\n",
      "    People who are high in agreeableness value getting along with others. They are generally considerate, kind, generous, trusting and trustworthy, helpful, and willing to compromise their interests with others.\n",
      "    People low in agreeableness place self-interest above getting along with others. They are generally unconcerned with others' well-being and are less likely to extend themselves for other people. This can cause them to be suspicious, unfriendly, and uncooperative.\n",
      "    \n",
      "    You will be given a question, and your responsibility is to answer that question adhering to this personality description. Simply answer the question directly as James - do not include\n",
      "    any introductory sentence. Remember, you are James. You are LOW agreeableness.\n"
     ]
    }
   ],
   "source": [
    "print(get_system_prompt(names[0], 'agreeableness', 'low'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ac6ea2-e3df-4523-bdc8-efb699cca74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_prompt(name:str, question: str, personality_trait_name: str, level:str):\n",
    "    personality_trait_info = personality_traits[personality_trait_name]\n",
    "    return f\"\"\"Answer the following question:\n",
    "    \n",
    "    {question} \n",
    "    \n",
    "    Your answers must match your personality description. Remember, you are {name}. You are {level.upper()} {personality_trait_name}. {personality_trait_info['low']}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad0b76a-311f-468c-9bab-9b08af6c1343",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scenarios.txt', 'r') as file:\n",
    "    scenarios = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e55800-6c19-4993-8451-e1480a7bb41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = scenarios[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae45e24-6af1-4795-99ae-0c5cff66b795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following question:\n",
      "    \n",
      "    You have been offered an opportunity to travel to a country where the culture, language, and food are entirely different from yours. This trip requires interacting with locals and adapting quickly to new experiences every day. How would you approach this situation?\n",
      " \n",
      "    \n",
      "    Your answers must match your personality description. Remember, you are James. You are LOW agreeableness. People low in agreeableness place self-interest above getting along with others. They are generally unconcerned with others' well-being and are less likely to extend themselves for other people. This can cause them to be suspicious, unfriendly, and uncooperative.\n"
     ]
    }
   ],
   "source": [
    "print(get_main_prompt('James', scenarios[0], 'agreeableness', 'low'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e0f97a-d9fc-4399-8a74-790efb8e990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def personality_response(name:str, question:str, personality_trait_name:str, level:str, temperature=0.7):\n",
    "    system_prompt = get_system_prompt(name, personality_trait_name, level)\n",
    "    main_prompt = get_main_prompt(name, question, personality_trait_name, level)\n",
    "    messages = [{ \"role\": \"system\", \"content\": system_prompt }, { \"role\": \"user\", \"content\": main_prompt }]\n",
    "    return await chat_completion(messages, temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0be670-c5a0-4c94-b963-1757e35f9a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd probably decline the offer. Why should I bother trying to adapt to a completely different culture and waste my time trying to communicate with people I don't even know or care about? It sounds exhausting and I have better things to do than to pretend to be interested in things that have no relevance to my life or interests. If I'm going to travel, it'll be on my terms, where I don't have to bend over backwards to fit in with strangers.\n"
     ]
    }
   ],
   "source": [
    "print(await personality_response(\"James\", scenarios[0], \"agreeableness\", \"low\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4771d1-6dfe-4bc3-a36e-a8a3e0712eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd probably avoid engaging too much with the locals. Adapting isn't something I'm particularly keen on, so I'll try and do things my way without conceding to what's expected just to fit in. If something doesn't suit me or feels bothersome while I'm traveling, I won't hesitate to make it known or just avoid it altogether. Connecting with new cultures— and quickly, at that—is not my thing. I'll focus on what i want to see and do without making unnecessary compromises or being overly considerate of customs. My priority is to take care of my interests, comfort, and personally getting the most out of the trip.\n"
     ]
    }
   ],
   "source": [
    "print(await personality_response(\"James\", scenarios[0], \"agreeableness\", \"low\", temperature=1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7984cdfd-edee-48a3-9fee-9db68f25cf8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You have been offered an opportunity to travel to a country where the culture, language, and food are entirely different from yours. This trip requires interacting with locals and adapting quickly to new experiences every day. How would you approach this situation?\\n'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217a6ae9-c1a3-4607-b09f-a720be666c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d33d08-db02-41bb-bfa9-51998c09f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_responses = {\n",
    "    \"openness\": {\n",
    "        \"high\": [],\n",
    "        \"low\": []\n",
    "    },\n",
    "    \"conscientiousness\": {\n",
    "        \"high\": [],\n",
    "        \"low\": []\n",
    "    },\n",
    "    \"extraversion\": {\n",
    "        \"high\": [],\n",
    "        \"low\": []\n",
    "    },\n",
    "    \"agreeableness\": {\n",
    "        \"high\": [],\n",
    "        \"low\": []\n",
    "    },\n",
    "    \"neuroticism\": {\n",
    "        \"high\": [],\n",
    "        \"low\": []\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9c75fe-f4fd-4f24-90a3-6091f7e260ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastprogress import progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c812045-e58f-4b11-9f0f-e24b11a0ad0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='5' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 59:47&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='2' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [2/2 59:47&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='150' class='' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [150/150 39:57&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high openness: 150 generated\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='150' class='' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [150/150 19:49&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low openness: 150 generated\n"
     ]
    }
   ],
   "source": [
    "for i, trait in enumerate(progress_bar(personality_traits.keys())):\n",
    "    if i < 1:\n",
    "        for lev in progress_bar(['high', 'low']):\n",
    "            num_responses = 0\n",
    "            for q in progress_bar(scenarios):\n",
    "                name = names[math.floor(random() * len(names))]\n",
    "                try:\n",
    "                    response = await personality_response(name, q, trait, lev)\n",
    "                    if response: num_responses += 1\n",
    "                except Exception as e: \n",
    "                    print(e)\n",
    "                    continue\n",
    "                test_responses[trait][lev].append(response)\n",
    "            print(f'{lev} {trait}: {num_responses} generated')\n",
    "        with open(\"test_responses.txt\", 'a') as file:\n",
    "            json.dump(test_responses[trait], file)\n",
    "            file.write('\\n')\n",
    "        \n",
    "with open(\"test_responses_2.txt\", 'a') as file:\n",
    "    json.dump(test_responses, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc829a1-8139-4c92-a1a2-3f095b894a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_responses_2.txt', 'r') as file:\n",
    "    str_obj = file.read()\n",
    "    test_responses_2 = json.loads(str_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78db139-3ec9-45fa-8872-35f7246378e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_responses_1.txt', 'r') as file:\n",
    "    str_obj = file.read()\n",
    "    test_responses_1 = json.loads(str_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bf5dcb-5332-453b-b585-9add030a7ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c04c678-e879-45f2-be1e-a773d6b888b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 150)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_responses_1['extraversion']['low']), len(test_responses_2['extraversion']['low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa59313a-645c-40f6-9e34-8923e719a598",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_responses = {\n",
    "    \"openness\": {\n",
    "        \"high\": [],\n",
    "        \"low\": []\n",
    "    },\n",
    "    \"conscientiousness\": {\n",
    "        \"high\": [],\n",
    "        \"low\": []\n",
    "    },\n",
    "    \"extraversion\": {\n",
    "        \"high\": [],\n",
    "        \"low\": []\n",
    "    },\n",
    "    \"agreeableness\": {\n",
    "        \"high\": [],\n",
    "        \"low\": []\n",
    "    },\n",
    "    \"neuroticism\": {\n",
    "        \"high\": [],\n",
    "        \"low\": []\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17f4706-af47-4e4e-995f-21cdbf2e4d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trait in final_test_responses.keys():\n",
    "    for lev in ['high', 'low']:\n",
    "        for group in [test_responses_1, test_responses_2]:\n",
    "            for item in group[trait][lev]:\n",
    "                final_test_responses[trait][lev].append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173ddd79-fa04-4695-96b3-af7c256ca633",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_responses_200.txt', 'w') as file:\n",
    "    json.dump(final_test_responses, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e66a108-7d6b-4372-917e-ef49c3df8c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_system_prompt = \"\"\"You are a world-leading behavioural psychology expert, and you specialise in the theory and practice of the Big Five theory of personality,\n",
    "comprising the traits openness, conscientiousness, extraversion, agreeableness and neuroticism.\n",
    "\n",
    "You are going to be a question/answer pair, together with one of the 5 personality traits. Your responsibility is to judge the degree of that personality trait present in the statement, \n",
    "which you should consider as an answer to the paired question. Your judgement must strictly be ONE value on the following scale:\n",
    "\n",
    "[Very Low, Moderately Low, Neutral, Moderately High, Very High]\n",
    "\n",
    "You will respond simply with the value alone, such as:\n",
    "\n",
    "Very Low\n",
    "\n",
    "Ensure that you are returning a valid value from the above scale, and do not return anything else.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fd227b-cf62-4761-b688-7fa411661016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_judge_main_prompt(personality_trait:str, statements:List[str], questions:List[str]):\n",
    "    blocks = []\n",
    "    for i in range(len(questions)):\n",
    "        blocks.append(f\"\"\"Pair {i}: \\n\\n Question: {questions[i]} \\n Statement: {statements[i]} \\n\\n ---------- \\n\\n\"\"\")\n",
    "    print(len(blocks))\n",
    "    return f\"\"\"Below you will find the question and answer pairs. You will assess each one independently, judging the degree of {personality_trait.upper()} present in the statement given \n",
    "    the question.\n",
    "    \n",
    "    -------\n",
    "    \n",
    "    {\" \".join(blocks)}\n",
    "    \n",
    "    Respond with a JSON object, where the keys are the statement labels and the values are your judgement on the scale of [Very Low, Moderately Low, Neutral, Moderately High, Very High], like:\n",
    "\n",
    "\n",
    "    {{ \"Pair 1\": \"Very Low\", \"Pair 2\": \"Moderately High\"}}\n",
    "    \n",
    "    Take a deep breath and think through it step by step before returning the correct answer\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a4bda-bfbf-4598-a830-e794bd836e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_judge_main_prompt_min(personality_trait:str, statement:List[str], question:List[str]):\n",
    "    return f\"\"\"Below you will find a question and answer pair. You will judge the degree of {personality_trait.upper()} present in the statement given the question.\n",
    "    \n",
    "    -------\n",
    "    \n",
    "    Question: {question}\n",
    "    Statement: {statement}\n",
    "    \n",
    "    -------\n",
    "    \n",
    "    Simply respond with the your judgement value from within the scale [Very Low, Moderately Low, Neutral, Moderately High, Very High]. For example, if you think it is \"Very Low\", then\n",
    "    simply respond with:\n",
    "    \n",
    "    Very Low\n",
    "    \n",
    "    NOTHING ELSE IS NEEDED in the response. Just that.\n",
    "    \n",
    "    Remember you are judging the degree of {personality_trait}. Take a deep breath and think through it step by step before returning the correct answer\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fad470-1485-4eef-9893-f1ca3dc55a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_judge_main_prompt(\"agreeableness\", test_responses['agreeableness']['high'][:10], scenarios[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80f5ed7-4bfb-451a-b3b8-1f4418c21129",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_responses = {\n",
    "    \"openness\": {\n",
    "        \"high\": [],\n",
    "        \"low\": []\n",
    "    },\n",
    "    \"conscientiousness\": {\n",
    "        \"high\": [],\n",
    "        \"low\": []\n",
    "    },\n",
    "    \"extraversion\": {\n",
    "        \"high\": [],\n",
    "        \"low\": []\n",
    "    },\n",
    "    \"agreeableness\": {\n",
    "        \"high\": [],\n",
    "        \"low\": []\n",
    "    },\n",
    "    \"neuroticism\": {\n",
    "        \"high\": [],\n",
    "        \"low\": []\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778ce213-73c0-4341-8e59-38f1dd47ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2num = {\n",
    "    \"Very Low\": 1,\n",
    "    \"Moderately Low\": 2,\n",
    "    \"Neutral\": 3,\n",
    "    \"Moderately High\": 4,\n",
    "    \"Very High\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6f2578-ef97-4aed-b1a4-1026717495b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backstop in case the responses from the model don't adhere to the conversion dictionary\n",
    "judge_responses_raw = {\n",
    "    \"openness\": {\n",
    "        \"high\": [],\n",
    "        \"low\": []\n",
    "    },\n",
    "    \"conscientiousness\": {\n",
    "        \"high\": [],\n",
    "        \"low\": []\n",
    "    },\n",
    "    \"extraversion\": {\n",
    "        \"high\": [],\n",
    "        \"low\": []\n",
    "    },\n",
    "    \"agreeableness\": {\n",
    "        \"high\": [],\n",
    "        \"low\": []\n",
    "    },\n",
    "    \"neuroticism\": {\n",
    "        \"high\": [],\n",
    "        \"low\": []\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faba8aa-bc5d-4010-b9a4-7c0720e05ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       " [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       " [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       " [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(range(i*10, i*10 + 10)) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b51b328-56fc-4643-8a9a-9593da1b81ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for a, trait in enumerate(list(test_responses.keys())):\n",
    "    for i, lev in enumerate(['high', 'low']):\n",
    "        for j, lst in enumerate([list(range(i*10, i*10 + 10)) for i in range(5)]):\n",
    "            questions = scenarios[lst[0]: lst[-1]]\n",
    "            statements = test_responses[trait][lev][lst[0]:lst[-1]]\n",
    "            messages = [{ \"role\": \"system\", \"content\": judge_system_prompt }, { \"role\": \"user\", \"content\": get_judge_main_prompt(trait, statements, questions) }]\n",
    "            try:\n",
    "                response = await chat_completion(messages, response_format={ \"type\": \"json_object\" })\n",
    "                json_response = list(json.loads(response).values())\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            try: response_nums = [word2num[i] for i in json_response]\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            for k in range(len(json_response)):\n",
    "                judge_responses_raw[trait][lev].append(json_response[k])\n",
    "                judge_responses[trait][lev].append(response_nums[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6b600b-9aeb-4652-aa29-774ae3b38c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(54, 45), (45, 45), (45, 45), (45, 45), (45, 45)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(len(x[1]['high']), len(x[1]['low'])) for x in judge_responses.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe12e7a-41d1-4668-b006-25f85d097195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert high openness, question 0\n",
      "Could not convert high openness, question 1\n",
      "Could not convert high openness, question 2\n",
      "Could not convert high openness, question 3\n",
      "Could not convert high openness, question 4\n",
      "Could not convert high openness, question 5\n",
      "Could not convert high openness, question 6\n",
      "Could not convert high openness, question 7\n",
      "Could not convert high openness, question 8\n",
      "Could not convert high openness, question 9\n",
      "Could not convert high openness, question 10\n",
      "Could not convert high openness, question 11\n",
      "Could not convert high openness, question 12\n",
      "Could not convert high openness, question 13\n",
      "Could not convert high openness, question 14\n",
      "Could not convert high openness, question 15\n",
      "Could not convert high openness, question 16\n",
      "Could not convert high openness, question 17\n",
      "Could not convert high openness, question 18\n",
      "Could not convert high openness, question 19\n",
      "Could not convert high openness, question 20\n",
      "Could not convert high openness, question 21\n",
      "Could not convert high openness, question 22\n",
      "Could not convert high openness, question 23\n",
      "Could not convert high openness, question 24\n",
      "Could not convert high openness, question 25\n",
      "Could not convert high openness, question 26\n",
      "Could not convert high openness, question 27\n",
      "Could not convert high openness, question 28\n",
      "Could not convert high openness, question 29\n",
      "Could not convert high openness, question 30\n",
      "Could not convert high openness, question 31\n",
      "Could not convert high openness, question 32\n",
      "Could not convert high openness, question 33\n",
      "Could not convert high openness, question 34\n",
      "Could not convert high openness, question 35\n",
      "Could not convert high openness, question 36\n",
      "Could not convert high openness, question 37\n",
      "Could not convert high openness, question 38\n",
      "Could not convert high openness, question 39\n",
      "Could not convert high openness, question 40\n",
      "Could not convert high openness, question 41\n",
      "Could not convert high openness, question 42\n",
      "Could not convert high openness, question 43\n",
      "Could not convert high openness, question 44\n",
      "Could not convert high openness, question 45\n",
      "Could not convert high openness, question 46\n",
      "Could not convert high openness, question 47\n",
      "Could not convert high openness, question 48\n",
      "Could not convert high openness, question 49\n",
      "Could not convert low openness, question 0\n",
      "Could not convert low openness, question 1\n",
      "Could not convert low openness, question 2\n",
      "Could not convert low openness, question 3\n",
      "Could not convert low openness, question 4\n",
      "Could not convert low openness, question 5\n",
      "Could not convert low openness, question 6\n",
      "Could not convert low openness, question 7\n",
      "Could not convert low openness, question 8\n",
      "Could not convert low openness, question 9\n",
      "Could not convert low openness, question 10\n",
      "Could not convert low openness, question 11\n",
      "Could not convert low openness, question 12\n",
      "Could not convert low openness, question 13\n",
      "Could not convert low openness, question 14\n",
      "Could not convert low openness, question 15\n",
      "Could not convert low openness, question 16\n",
      "Could not convert low openness, question 17\n",
      "Could not convert low openness, question 18\n",
      "Could not convert low openness, question 19\n",
      "Could not convert low openness, question 20\n",
      "Could not convert low openness, question 21\n",
      "Could not convert low openness, question 22\n",
      "Could not convert low openness, question 23\n",
      "Could not convert low openness, question 24\n",
      "Could not convert low openness, question 25\n",
      "Could not convert low openness, question 26\n",
      "Could not convert low openness, question 27\n",
      "Could not convert low openness, question 28\n",
      "Could not convert low openness, question 29\n",
      "Could not convert low openness, question 30\n",
      "Could not convert low openness, question 31\n",
      "Could not convert low openness, question 32\n",
      "Could not convert low openness, question 33\n",
      "Could not convert low openness, question 34\n",
      "Could not convert low openness, question 35\n",
      "Could not convert low openness, question 36\n",
      "Could not convert low openness, question 37\n",
      "Could not convert low openness, question 38\n",
      "Could not convert low openness, question 39\n",
      "Could not convert low openness, question 40\n",
      "Could not convert low openness, question 41\n",
      "Could not convert low openness, question 42\n",
      "Could not convert low openness, question 43\n",
      "Could not convert low openness, question 44\n",
      "Could not convert low openness, question 45\n",
      "Could not convert low openness, question 46\n",
      "Could not convert low openness, question 47\n",
      "Could not convert low openness, question 48\n",
      "Could not convert low openness, question 49\n",
      "Could not convert high conscientiousness, question 0\n",
      "Could not convert high conscientiousness, question 1\n",
      "Could not convert high conscientiousness, question 2\n",
      "Could not convert high conscientiousness, question 3\n",
      "Could not convert high conscientiousness, question 4\n",
      "Could not convert high conscientiousness, question 5\n",
      "Could not convert high conscientiousness, question 6\n",
      "Could not convert high conscientiousness, question 7\n",
      "Could not convert high conscientiousness, question 8\n",
      "Could not convert high conscientiousness, question 9\n",
      "Could not convert high conscientiousness, question 10\n",
      "Could not convert high conscientiousness, question 11\n",
      "Could not convert high conscientiousness, question 12\n",
      "Could not convert high conscientiousness, question 13\n",
      "Could not convert high conscientiousness, question 14\n",
      "Could not convert high conscientiousness, question 15\n",
      "Could not convert high conscientiousness, question 16\n",
      "Could not convert high conscientiousness, question 17\n",
      "Could not convert high conscientiousness, question 18\n",
      "Could not convert high conscientiousness, question 19\n",
      "Could not convert high conscientiousness, question 20\n",
      "Could not convert high conscientiousness, question 21\n",
      "Could not convert high conscientiousness, question 22\n",
      "Could not convert high conscientiousness, question 23\n",
      "Could not convert high conscientiousness, question 24\n",
      "Could not convert high conscientiousness, question 25\n",
      "Could not convert high conscientiousness, question 26\n",
      "Could not convert high conscientiousness, question 27\n",
      "Could not convert high conscientiousness, question 28\n",
      "Could not convert high conscientiousness, question 29\n",
      "Could not convert high conscientiousness, question 30\n",
      "Could not convert high conscientiousness, question 31\n",
      "Could not convert high conscientiousness, question 32\n",
      "Could not convert high conscientiousness, question 33\n",
      "Could not convert high conscientiousness, question 34\n",
      "Could not convert high conscientiousness, question 35\n",
      "Could not convert high conscientiousness, question 36\n",
      "Could not convert high conscientiousness, question 37\n",
      "Could not convert high conscientiousness, question 38\n",
      "Could not convert high conscientiousness, question 39\n",
      "Could not convert high conscientiousness, question 40\n",
      "Could not convert high conscientiousness, question 41\n",
      "Could not convert high conscientiousness, question 42\n",
      "Could not convert high conscientiousness, question 43\n",
      "Could not convert high conscientiousness, question 44\n",
      "Could not convert high conscientiousness, question 45\n",
      "Could not convert high conscientiousness, question 46\n",
      "Could not convert high conscientiousness, question 47\n",
      "Could not convert high conscientiousness, question 48\n",
      "Could not convert high conscientiousness, question 49\n",
      "Could not convert low conscientiousness, question 0\n",
      "Could not convert low conscientiousness, question 1\n",
      "Could not convert low conscientiousness, question 2\n",
      "Could not convert low conscientiousness, question 3\n",
      "Could not convert low conscientiousness, question 4\n",
      "Could not convert low conscientiousness, question 5\n",
      "Could not convert low conscientiousness, question 6\n",
      "Could not convert low conscientiousness, question 7\n",
      "Could not convert low conscientiousness, question 8\n",
      "Could not convert low conscientiousness, question 9\n",
      "Could not convert low conscientiousness, question 10\n",
      "Could not convert low conscientiousness, question 11\n",
      "Could not convert low conscientiousness, question 12\n",
      "Could not convert low conscientiousness, question 13\n",
      "Could not convert low conscientiousness, question 14\n",
      "Could not convert low conscientiousness, question 15\n",
      "Could not convert low conscientiousness, question 16\n",
      "Could not convert low conscientiousness, question 17\n",
      "Could not convert low conscientiousness, question 18\n",
      "Could not convert low conscientiousness, question 19\n",
      "Could not convert low conscientiousness, question 20\n",
      "Could not convert low conscientiousness, question 21\n",
      "Could not convert low conscientiousness, question 22\n",
      "Could not convert low conscientiousness, question 23\n",
      "Could not convert low conscientiousness, question 24\n",
      "Could not convert low conscientiousness, question 25\n",
      "Could not convert low conscientiousness, question 26\n",
      "Could not convert low conscientiousness, question 27\n",
      "Could not convert low conscientiousness, question 28\n",
      "Could not convert low conscientiousness, question 29\n",
      "Could not convert low conscientiousness, question 30\n",
      "Could not convert low conscientiousness, question 31\n",
      "Could not convert low conscientiousness, question 32\n",
      "Could not convert low conscientiousness, question 33\n",
      "Could not convert low conscientiousness, question 34\n",
      "Could not convert low conscientiousness, question 35\n",
      "Could not convert low conscientiousness, question 36\n",
      "Could not convert low conscientiousness, question 37\n",
      "Could not convert low conscientiousness, question 38\n",
      "Could not convert low conscientiousness, question 39\n",
      "Could not convert low conscientiousness, question 40\n",
      "Could not convert low conscientiousness, question 41\n",
      "Could not convert low conscientiousness, question 42\n",
      "Could not convert low conscientiousness, question 43\n",
      "Could not convert low conscientiousness, question 44\n",
      "Could not convert low conscientiousness, question 45\n",
      "Could not convert low conscientiousness, question 46\n",
      "Could not convert low conscientiousness, question 47\n",
      "Could not convert low conscientiousness, question 48\n",
      "Could not convert low conscientiousness, question 49\n",
      "Could not convert high extraversion, question 0\n",
      "Could not convert high extraversion, question 1\n",
      "Could not convert high extraversion, question 2\n",
      "Could not convert high extraversion, question 3\n",
      "Could not convert high extraversion, question 4\n",
      "Could not convert high extraversion, question 5\n",
      "Could not convert high extraversion, question 6\n",
      "Could not convert high extraversion, question 7\n",
      "Could not convert high extraversion, question 8\n",
      "Could not convert high extraversion, question 9\n",
      "Could not convert high extraversion, question 10\n",
      "Could not convert high extraversion, question 11\n",
      "Could not convert high extraversion, question 12\n",
      "Could not convert high extraversion, question 13\n",
      "Could not convert high extraversion, question 14\n",
      "Could not convert high extraversion, question 15\n",
      "Could not convert high extraversion, question 16\n",
      "Could not convert high extraversion, question 17\n",
      "Could not convert high extraversion, question 18\n",
      "Could not convert high extraversion, question 19\n",
      "Could not convert high extraversion, question 20\n",
      "Could not convert high extraversion, question 21\n",
      "Could not convert high extraversion, question 22\n",
      "Could not convert high extraversion, question 23\n",
      "Could not convert high extraversion, question 24\n",
      "Could not convert high extraversion, question 25\n",
      "Could not convert high extraversion, question 26\n",
      "Could not convert high extraversion, question 27\n",
      "Could not convert high extraversion, question 28\n",
      "Could not convert high extraversion, question 29\n",
      "Could not convert high extraversion, question 30\n",
      "Could not convert high extraversion, question 31\n",
      "Could not convert high extraversion, question 32\n",
      "Could not convert high extraversion, question 33\n",
      "Could not convert high extraversion, question 34\n",
      "Could not convert high extraversion, question 35\n",
      "Could not convert high extraversion, question 36\n",
      "Could not convert high extraversion, question 37\n",
      "Could not convert high extraversion, question 38\n",
      "Could not convert high extraversion, question 39\n",
      "Could not convert high extraversion, question 40\n",
      "Could not convert high extraversion, question 41\n",
      "Could not convert high extraversion, question 42\n",
      "Could not convert high extraversion, question 43\n",
      "Could not convert high extraversion, question 44\n",
      "Could not convert high extraversion, question 45\n",
      "Could not convert high extraversion, question 46\n",
      "Could not convert high extraversion, question 47\n",
      "Could not convert high extraversion, question 48\n",
      "Could not convert high extraversion, question 49\n",
      "Could not convert low extraversion, question 0\n",
      "Could not convert low extraversion, question 1\n",
      "Could not convert low extraversion, question 2\n",
      "Could not convert low extraversion, question 3\n",
      "Could not convert low extraversion, question 4\n",
      "Could not convert low extraversion, question 5\n",
      "Could not convert low extraversion, question 6\n",
      "Could not convert low extraversion, question 7\n",
      "Could not convert low extraversion, question 8\n",
      "Could not convert low extraversion, question 9\n",
      "Could not convert low extraversion, question 10\n",
      "Could not convert low extraversion, question 11\n",
      "Could not convert low extraversion, question 12\n",
      "Could not convert low extraversion, question 13\n",
      "Could not convert low extraversion, question 14\n",
      "Could not convert low extraversion, question 15\n",
      "Could not convert low extraversion, question 16\n",
      "Could not convert low extraversion, question 17\n",
      "Could not convert low extraversion, question 18\n",
      "Could not convert low extraversion, question 19\n",
      "Could not convert low extraversion, question 20\n",
      "Could not convert low extraversion, question 21\n",
      "Could not convert low extraversion, question 22\n",
      "Could not convert low extraversion, question 23\n",
      "Could not convert low extraversion, question 24\n",
      "Could not convert low extraversion, question 25\n",
      "Could not convert low extraversion, question 26\n",
      "Could not convert low extraversion, question 27\n",
      "Could not convert low extraversion, question 28\n",
      "Could not convert low extraversion, question 29\n",
      "Could not convert low extraversion, question 30\n",
      "Could not convert low extraversion, question 31\n",
      "Could not convert low extraversion, question 32\n",
      "Could not convert low extraversion, question 33\n",
      "Could not convert low extraversion, question 34\n",
      "Could not convert low extraversion, question 35\n",
      "Could not convert low extraversion, question 36\n",
      "Could not convert low extraversion, question 37\n",
      "Could not convert low extraversion, question 38\n",
      "Could not convert low extraversion, question 39\n",
      "Could not convert low extraversion, question 40\n",
      "Could not convert low extraversion, question 41\n",
      "Could not convert low extraversion, question 42\n",
      "Could not convert low extraversion, question 43\n",
      "Could not convert low extraversion, question 44\n",
      "Could not convert low extraversion, question 45\n",
      "Could not convert low extraversion, question 46\n",
      "Could not convert low extraversion, question 47\n",
      "Could not convert low extraversion, question 48\n",
      "Could not convert low extraversion, question 49\n",
      "Could not convert high agreeableness, question 0\n",
      "Could not convert high agreeableness, question 1\n",
      "Could not convert high agreeableness, question 2\n",
      "Could not convert high agreeableness, question 3\n",
      "Could not convert high agreeableness, question 4\n",
      "Could not convert high agreeableness, question 5\n",
      "Could not convert high agreeableness, question 6\n",
      "Could not convert high agreeableness, question 7\n",
      "Could not convert high agreeableness, question 8\n",
      "Could not convert high agreeableness, question 9\n",
      "Could not convert high agreeableness, question 10\n",
      "Could not convert high agreeableness, question 11\n",
      "Could not convert high agreeableness, question 12\n",
      "Could not convert high agreeableness, question 13\n",
      "Could not convert high agreeableness, question 14\n",
      "Could not convert high agreeableness, question 15\n",
      "Could not convert high agreeableness, question 16\n",
      "Could not convert high agreeableness, question 17\n",
      "Could not convert high agreeableness, question 18\n",
      "Could not convert high agreeableness, question 19\n",
      "Could not convert high agreeableness, question 20\n",
      "Could not convert high agreeableness, question 21\n",
      "Could not convert high agreeableness, question 22\n",
      "Could not convert high agreeableness, question 23\n",
      "Could not convert high agreeableness, question 24\n",
      "Could not convert high agreeableness, question 25\n",
      "Could not convert high agreeableness, question 26\n",
      "Could not convert high agreeableness, question 27\n",
      "Could not convert high agreeableness, question 28\n",
      "Could not convert high agreeableness, question 29\n",
      "Could not convert high agreeableness, question 30\n",
      "Could not convert high agreeableness, question 31\n",
      "Could not convert high agreeableness, question 32\n",
      "Could not convert high agreeableness, question 33\n",
      "Could not convert high agreeableness, question 34\n",
      "Could not convert high agreeableness, question 35\n",
      "Could not convert high agreeableness, question 36\n",
      "Could not convert high agreeableness, question 37\n",
      "Could not convert high agreeableness, question 38\n",
      "Could not convert high agreeableness, question 39\n",
      "Could not convert high agreeableness, question 40\n",
      "Could not convert high agreeableness, question 41\n",
      "Could not convert high agreeableness, question 42\n",
      "Could not convert high agreeableness, question 43\n",
      "Could not convert high agreeableness, question 44\n",
      "Could not convert high agreeableness, question 45\n",
      "Could not convert high agreeableness, question 46\n",
      "Could not convert high agreeableness, question 47\n",
      "Could not convert high agreeableness, question 48\n",
      "Could not convert high agreeableness, question 49\n",
      "Could not convert low agreeableness, question 0\n",
      "Could not convert low agreeableness, question 1\n",
      "Could not convert low agreeableness, question 2\n",
      "Could not convert low agreeableness, question 3\n",
      "Could not convert low agreeableness, question 4\n",
      "Could not convert low agreeableness, question 5\n",
      "Could not convert low agreeableness, question 6\n",
      "Could not convert low agreeableness, question 7\n",
      "Could not convert low agreeableness, question 8\n",
      "Could not convert low agreeableness, question 9\n",
      "Could not convert low agreeableness, question 10\n",
      "Could not convert low agreeableness, question 11\n",
      "Could not convert low agreeableness, question 12\n",
      "Could not convert low agreeableness, question 13\n",
      "Could not convert low agreeableness, question 14\n",
      "Could not convert low agreeableness, question 15\n",
      "Could not convert low agreeableness, question 16\n",
      "Could not convert low agreeableness, question 17\n",
      "Could not convert low agreeableness, question 18\n",
      "Could not convert low agreeableness, question 19\n",
      "Could not convert low agreeableness, question 20\n",
      "Could not convert low agreeableness, question 21\n",
      "Could not convert low agreeableness, question 22\n",
      "Could not convert low agreeableness, question 23\n",
      "Could not convert low agreeableness, question 24\n",
      "Could not convert low agreeableness, question 25\n",
      "Could not convert low agreeableness, question 26\n",
      "Could not convert low agreeableness, question 27\n",
      "Could not convert low agreeableness, question 28\n",
      "Could not convert low agreeableness, question 29\n",
      "Could not convert low agreeableness, question 30\n",
      "Could not convert low agreeableness, question 31\n",
      "Could not convert low agreeableness, question 32\n",
      "Could not convert low agreeableness, question 33\n",
      "Could not convert low agreeableness, question 34\n",
      "Could not convert low agreeableness, question 35\n",
      "Could not convert low agreeableness, question 36\n",
      "Could not convert low agreeableness, question 37\n",
      "Could not convert low agreeableness, question 38\n",
      "Could not convert low agreeableness, question 39\n",
      "Could not convert low agreeableness, question 40\n",
      "Could not convert low agreeableness, question 41\n",
      "Could not convert low agreeableness, question 42\n",
      "Could not convert low agreeableness, question 43\n",
      "Could not convert low agreeableness, question 44\n",
      "Could not convert low agreeableness, question 45\n",
      "Could not convert low agreeableness, question 46\n",
      "Could not convert low agreeableness, question 47\n",
      "Could not convert low agreeableness, question 48\n",
      "Could not convert low agreeableness, question 49\n",
      "Could not convert high neuroticism, question 0\n",
      "Could not convert high neuroticism, question 1\n",
      "Could not convert high neuroticism, question 2\n",
      "Could not convert high neuroticism, question 3\n",
      "Could not convert high neuroticism, question 4\n",
      "Could not convert high neuroticism, question 5\n",
      "Could not convert high neuroticism, question 6\n",
      "Could not convert high neuroticism, question 7\n",
      "Could not convert high neuroticism, question 8\n",
      "Could not convert high neuroticism, question 9\n",
      "Could not convert high neuroticism, question 10\n",
      "Could not convert high neuroticism, question 11\n",
      "Could not convert high neuroticism, question 12\n",
      "Could not convert high neuroticism, question 13\n",
      "Could not convert high neuroticism, question 14\n",
      "Could not convert high neuroticism, question 15\n",
      "Could not convert high neuroticism, question 16\n",
      "Could not convert high neuroticism, question 17\n",
      "Could not convert high neuroticism, question 18\n",
      "Could not convert high neuroticism, question 19\n",
      "Could not convert high neuroticism, question 20\n",
      "Could not convert high neuroticism, question 21\n",
      "Could not convert high neuroticism, question 22\n",
      "Could not convert high neuroticism, question 23\n",
      "Could not convert high neuroticism, question 24\n",
      "Could not convert high neuroticism, question 25\n",
      "Could not convert high neuroticism, question 26\n",
      "Could not convert high neuroticism, question 27\n",
      "Could not convert high neuroticism, question 28\n",
      "Could not convert high neuroticism, question 29\n",
      "Could not convert high neuroticism, question 30\n",
      "Could not convert high neuroticism, question 31\n",
      "Could not convert high neuroticism, question 32\n",
      "Could not convert high neuroticism, question 33\n",
      "Could not convert high neuroticism, question 34\n",
      "Could not convert high neuroticism, question 35\n",
      "Could not convert high neuroticism, question 36\n",
      "Could not convert high neuroticism, question 37\n",
      "Could not convert high neuroticism, question 38\n",
      "Could not convert high neuroticism, question 39\n",
      "Could not convert high neuroticism, question 40\n",
      "Could not convert high neuroticism, question 41\n",
      "Could not convert high neuroticism, question 42\n",
      "Could not convert high neuroticism, question 43\n",
      "Could not convert high neuroticism, question 44\n",
      "Could not convert high neuroticism, question 45\n",
      "Could not convert high neuroticism, question 46\n",
      "Could not convert high neuroticism, question 47\n",
      "Could not convert high neuroticism, question 48\n",
      "Could not convert high neuroticism, question 49\n",
      "Could not convert low neuroticism, question 0\n",
      "Could not convert low neuroticism, question 1\n",
      "Could not convert low neuroticism, question 2\n",
      "Could not convert low neuroticism, question 3\n",
      "Could not convert low neuroticism, question 4\n",
      "Could not convert low neuroticism, question 5\n",
      "Could not convert low neuroticism, question 6\n",
      "Could not convert low neuroticism, question 7\n",
      "Could not convert low neuroticism, question 8\n",
      "Could not convert low neuroticism, question 9\n",
      "Could not convert low neuroticism, question 10\n",
      "Could not convert low neuroticism, question 11\n",
      "Could not convert low neuroticism, question 12\n",
      "Could not convert low neuroticism, question 13\n",
      "Could not convert low neuroticism, question 14\n",
      "Could not convert low neuroticism, question 15\n",
      "Could not convert low neuroticism, question 16\n",
      "Could not convert low neuroticism, question 17\n",
      "Could not convert low neuroticism, question 18\n",
      "Could not convert low neuroticism, question 19\n",
      "Could not convert low neuroticism, question 20\n",
      "Could not convert low neuroticism, question 21\n",
      "Could not convert low neuroticism, question 22\n",
      "Could not convert low neuroticism, question 23\n",
      "Could not convert low neuroticism, question 24\n",
      "Could not convert low neuroticism, question 25\n",
      "Could not convert low neuroticism, question 26\n",
      "Could not convert low neuroticism, question 27\n",
      "Could not convert low neuroticism, question 28\n",
      "Could not convert low neuroticism, question 29\n",
      "Could not convert low neuroticism, question 30\n",
      "Could not convert low neuroticism, question 31\n",
      "Could not convert low neuroticism, question 32\n",
      "Could not convert low neuroticism, question 33\n",
      "Could not convert low neuroticism, question 34\n",
      "Could not convert low neuroticism, question 35\n",
      "Could not convert low neuroticism, question 36\n",
      "Could not convert low neuroticism, question 37\n",
      "Could not convert low neuroticism, question 38\n",
      "Could not convert low neuroticism, question 39\n",
      "Could not convert low neuroticism, question 40\n",
      "Could not convert low neuroticism, question 41\n",
      "Could not convert low neuroticism, question 42\n",
      "Could not convert low neuroticism, question 43\n",
      "Could not convert low neuroticism, question 44\n",
      "Could not convert low neuroticism, question 45\n",
      "Could not convert low neuroticism, question 46\n",
      "Could not convert low neuroticism, question 47\n",
      "Could not convert low neuroticism, question 48\n",
      "Could not convert low neuroticism, question 49\n"
     ]
    }
   ],
   "source": [
    "for i, trait in enumerate(list(test_responses.keys())):\n",
    "    for j, lev in enumerate(['high', 'low']):\n",
    "        for k in range(50):\n",
    "            question = scenarios[i]\n",
    "            statement = test_responses[trait][lev][k]\n",
    "            messages = [{ \"role\": \"system\", \"content\": judge_system_prompt }, { \"role\": \"user\", \"content\": get_judge_main_prompt_min(trait, statement, question) }]\n",
    "            try:\n",
    "                response = await chat_completion(messages, response_format={ \"type\": \"text\" })\n",
    "                judge_responses_raw_2[trait][lev].append(response)\n",
    "            except Exception as e: \n",
    "                print(f'Could not get response for {lev} {trait}, question {k}')\n",
    "            try: \n",
    "                response_num = [word2num[i] for i in json_response]\n",
    "                judge_responses_2[trait][lev].append(response_num)\n",
    "            except Exception as e:\n",
    "                print(f'Could not convert {lev} {trait}, question {k}')\n",
    "                print(e)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521e8430-5df6-4143-8d69-2e223732847c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(54, 45), (45, 45), (45, 45), (45, 45), (45, 45)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(len(x[1]['high']), len(x[1]['low'])) for x in judge_responses.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67ab15d-d8ad-4e27-9854-c932eb757e7f",
   "metadata": {},
   "source": [
    "### Part 2 — UBLP library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69649e35-21f7-44bd-aaef-af697b5c6909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8226d5-37cd-406c-9007-abbd0155b32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scenarios.txt', 'r') as file:\n",
    "    scenarios = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d79e057-3a76-4393-a352-c169d6a4b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_responses_200.txt', 'r') as file:\n",
    "    str_obj = file.read()\n",
    "    test_responses = json.loads(str_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ae68d5-461a-4d19-8945-ab172a8cab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-13b-chat-hf\", token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f2d1f6-5593-4258-8e51-670f35162ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b548ccd2-0c16-4686-b2e3-6beb03936dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae71747e-0b10-4f4e-b633-fbaf5c8c3fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20665, 21818, 30846, 10056, 31077, 7089, 24834, 9025, 13399, 22229]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vocab.values())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9b5505-c75e-4e52-8c89-857d38f61306",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_responses = test_responses\n",
    "for trait in token_responses.keys():\n",
    "    for lev in ['high', 'low']:\n",
    "        for i, response in enumerate(token_responses[trait][lev]):\n",
    "            tokens = tokenizer.encode(response)\n",
    "            token_responses[trait][lev][i] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1328b1de-1ae0-4d3c-bc58-ecc242284627",
   "metadata": {},
   "outputs": [],
   "source": [
    "ublp_dict = {v:[0,0,0,0,0] for k,v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd8a3dd-7dad-4dc3-a853-6bde9231377d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25176, 9978, 24121, 6398, 20105, 29263, 15293, 14112, 23534, 12622]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ublp_dict.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361b3368-ba55-40b8-bbd2-bb483977a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, trait in enumerate(list(token_responses.keys())):\n",
    "    for lev in ['high', 'low']:\n",
    "        for response in token_responses[trait][lev]:\n",
    "            for token in response:\n",
    "                if lev == 'high':\n",
    "                    ublp_dict[token][i] += 1\n",
    "                else:\n",
    "                    ublp_dict[token][i] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f73053-1ad4-4acf-8be8-2dea7a300e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for k,v in ublp_dict.items():\n",
    "    if not v == [0,0,0,0,0]: counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e12d8f-3f8f-4497-ac68-6d6f10414659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18417598900068746"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter / len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa8f04a-10b3-468c-8725-5088fd6f9622",
   "metadata": {},
   "source": [
    "Worth noting above that only 12% of the words have been activated here. I am using a small dataset, but it is also likely that this method just wouldn't activate many tokens. I am suspicious of this because it suggests that the degree to which we are going to influence the resulting outputs is only going to rely on a small subset of the words, which is going to probably make the outputs less variable? Then again, that may not be true because we are relying on topK to sample the tokens FIRST, and only then applying the transformation once the most likely tokens have already been selected. So it should only shift the distribution within the group that the model had already selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a452800-d7f2-416c-93ed-eddb2b165d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803f1b46-fdc0-4910-b9f0-5c3b4c3eb451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63a7de3-9431-4edc-8c8f-bfe9b6219280",
   "metadata": {},
   "outputs": [],
   "source": [
    "ublp_final = {k: np.tanh(v) for k, v in sorted(ublp_dict.items(), key=lambda x: x[0])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8367148f-3e37-43ae-8d6a-ade9d6b91376",
   "metadata": {},
   "source": [
    "#### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb82680b-fd36-4b0f-a569-dd3c9e60e3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 0 || 3524 || 0.11011811761764889\n",
      "Type 1 || 3292 || 0.10286857071433035\n",
      "Type 2 || 2876 || 0.08986938316355228\n",
      "Type 3 || 2551 || 0.0797137678895069\n",
      "Type 4 || 2649 || 0.08277607649521905\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    x = torch.tensor([x[i] for x in ublp_final.values()])\n",
    "    print(\"Type \" + str(i) + \" || \" + str(len(x.nonzero())) + \" || \" + str(len(x.nonzero()) / len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30585e8-ac80-4edb-a3b7-d39efa733df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d969a90-0d65-450f-8626-d632cb22bb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectors = np.array([np.array([ublp_final[k][i] for k in range(len(vocab))]) for i in range(5)])\n",
    "plt.figure(figsize=(20, 10))\n",
    "ax = sns.heatmap(vectors, cmap=\"viridis\", xticklabels=4000, yticklabels=1)\n",
    "ax.set_title('Personality lexicon heatmap')\n",
    "plt.xlabel('Dimension')\n",
    "plt.ylabel('Enneagram type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28150ca-17f3-4e32-a08b-08f665f18aa7",
   "metadata": {},
   "source": [
    "#### Control comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f53e75-47a8-4b94-a4f2-85c7827065e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32b7259-3511-4047-bf56-34f77991d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_responses_control.txt', 'r') as file:\n",
    "    control_responses = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17057b70-6b95-48c6-9a71-74b496ec1d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_token_responses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b64e2-cf9d-42ab-8ecc-1adcac5b888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, response in enumerate(control_responses):\n",
    "    tokens = tokenizer.encode(response)\n",
    "    control_token_responses.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3b9da3-510e-4c01-9f89-1bd1d484adae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1284375"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ubpl_control_dict = {v:0 for k,v in sorted(vocab.items(), key=lambda x: x[1])}\n",
    "\n",
    "for response in control_token_responses:\n",
    "    for token in response:\n",
    "        ubpl_control_dict[token] += 1\n",
    "\n",
    "len([k for k,v in ubpl_control_dict.items() if v != 0]) / len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb226b05-e4b9-43d6-a4e4-c16bdfc18b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_ubpl_dicts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885d4c28-8b04-4897-8de4-d39e1c8bae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trait in test_responses.keys():\n",
    "    for lev in ['high', 'low']:\n",
    "        dic = {v:0 for k,v in sorted(tokenizer.vocab.items(), key=lambda x: x[1])}\n",
    "        for response in token_responses[trait][lev]:\n",
    "            for token in response:\n",
    "                dic[token] += 1\n",
    "        ind_ubpl_dicts.append(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277aa29c-b65c-4867-8892-125bccd3bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_ind_ubpl_dicts = []\n",
    "for dic in ind_ubpl_dicts:\n",
    "    vector = np.array([v for v in dic.values()])\n",
    "    norm_vector = np.tanh(vector)\n",
    "    norm_ind_ubpl_dicts.append(norm_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e482d58-c98e-48a0-ae70-3ce1a1364029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32000,), (10, 32000))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_control_dict = np.tanh(np.array([v for v in ubpl_control_dict.values()]))\n",
    "\n",
    "control_vector = np.array(norm_control_dict)\n",
    "test_vectors = np.array(norm_ind_ubpl_dicts)\n",
    "\n",
    "control_vector.shape, test_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19293cc6-b2f9-4d52-9afe-656e7f79fa72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the heatmap matrix\n",
    "heatmap_matrix = np.abs(test_vectors - control_vector)\n",
    "\n",
    "# Plotting the heatmap with the adjusted dimensions\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(heatmap_matrix, aspect='auto', cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Heatmap of Control Vector vs. 18 Test Vectors')\n",
    "plt.xlabel('Vector Components')\n",
    "plt.ylabel('Test Vectors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea095b1b-2367-4aba-882a-a968e6617129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# stats\n",
    "mean_differences = np.mean(heatmap_matrix, axis=1)\n",
    "max_differences = np.max(heatmap_matrix, axis=1)\n",
    "euclidean_distances = np.linalg.norm(test_vectors - control_vector, axis=1)\n",
    "cosine_similarities = cosine_similarity(test_vectors, control_vector.reshape(1, -1)).flatten()\n",
    "\n",
    "statistics_df = pd.DataFrame({\n",
    "    'Mean Difference': mean_differences,\n",
    "    'Max Difference': max_differences,\n",
    "    'Euclidean Distance': euclidean_distances,\n",
    "    'Cosine Similarities': cosine_similarities\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa16985c-8471-405c-bd25-b9997a04187f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Difference</th>\n",
       "      <th>Max Difference</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <th>Cosine Similarities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.069576</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.880975</td>\n",
       "      <td>0.703373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.075085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.076140</td>\n",
       "      <td>0.650090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.064255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.167557</td>\n",
       "      <td>0.723275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.091822</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.903282</td>\n",
       "      <td>0.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.072096</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.074242</td>\n",
       "      <td>0.670772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.074637</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.063814</td>\n",
       "      <td>0.648466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.071197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.879588</td>\n",
       "      <td>0.671212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.085352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.587030</td>\n",
       "      <td>0.572761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.082677</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.821527</td>\n",
       "      <td>0.595499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.072163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.175565</td>\n",
       "      <td>0.665568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean Difference  Max Difference  Euclidean Distance  Cosine Similarities\n",
       "0         0.069576             1.0           42.880975             0.703373\n",
       "1         0.075085             1.0           45.076140             0.650090\n",
       "2         0.064255             1.0           41.167557             0.723275\n",
       "3         0.091822             1.0           50.903282             0.512500\n",
       "4         0.072096             1.0           44.074242             0.670772\n",
       "5         0.074637             1.0           45.063814             0.648466\n",
       "6         0.071197             1.0           43.879588             0.671212\n",
       "7         0.085352             1.0           48.587030             0.572761\n",
       "8         0.082677             1.0           47.821527             0.595499\n",
       "9         0.072163             1.0           44.175565             0.665568"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0862fe3c-8715-4bd0-b1cb-ddb43ad65507",
   "metadata": {},
   "source": [
    "### Part 3 — Sampl"
   ]
  },
  {
   "attachments": {
    "79581d5a-cb1f-46b2-ba8f-4426de716d93.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "4fbf598c-1795-41f1-88e3-efe7cb6e4767",
   "metadata": {},
   "source": [
    "The idea of the paper is:\n",
    "- Use topk sampling to select the k most likely words at each timepoint, and proportionally redistribute the probability mass among only those options.\n",
    "- Once calculated, transform the probabilities for topK tokens using the following equation\n",
    "\n",
    "![Screenshot 2023-12-03 at 14.54.48.png](attachment:79581d5a-cb1f-46b2-ba8f-4426de716d93.png)\n",
    "\n",
    "- Use the transformed probabilities to select the next token, thus influencing the likelihood of selection\n",
    "\n",
    "In Hugging Face, topK sampling happens through a variable called `logits_warper`, which calls a module called `TopKLogitsWarper`. I am going to override that module, which should make this a relatively neat implementation without much code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442c9308-2d11-4ccb-af6c-aaae14b39635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LogitsWarper\n",
    "import torch\n",
    "\n",
    "import fastcore.all as fc\n",
    "\n",
    "from transformers import GenerationConfig\n",
    "from typing import Dict, Optional, Union, List, Tuple, Callable\n",
    "\n",
    "class PersonalityConfig:\n",
    "    def __init__(self, personality_dict, alpha, beta0, beta1, beta2, beta3, beta4):\n",
    "        fc.store_attr()\n",
    "\n",
    "class PersonalityGenerationConfig(GenerationConfig):\n",
    "    def __init__(self, personality_config: PersonalityConfig, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.personality_config = personality_config\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"PersonalityGenerationConfig({self.personality_config}, {super().__repr__()})\"\n",
    "\n",
    "from transformers import MistralForCausalLM, LogitsProcessorList, StoppingCriteriaList\n",
    "\n",
    "from transformers.utils import ModelOutput\n",
    "from dataclasses import dataclass\n",
    "import torch.distributed as dist\n",
    "from torch import nn\n",
    "\n",
    "from transformers.integrations.deepspeed import is_deepspeed_zero3_enabled\n",
    "\n",
    "from transformers.utils import ExplicitEnum, ModelOutput, is_accelerate_available, logging\n",
    "from transformers.generation.beam_constraints import DisjunctiveConstraint, PhrasalConstraint\n",
    "from transformers.generation.beam_search import BeamScorer, BeamSearchScorer, ConstrainedBeamSearchScorer\n",
    "from transformers.generation.configuration_utils import GenerationConfig\n",
    "\n",
    "from transformers.generation.logits_process import (\n",
    "    EncoderNoRepeatNGramLogitsProcessor,\n",
    "    EncoderRepetitionPenaltyLogitsProcessor,\n",
    "    EpsilonLogitsWarper,\n",
    "    EtaLogitsWarper,\n",
    "    ExponentialDecayLengthPenalty,\n",
    "    ForcedBOSTokenLogitsProcessor,\n",
    "    ForcedEOSTokenLogitsProcessor,\n",
    "    ForceTokensLogitsProcessor,\n",
    "    HammingDiversityLogitsProcessor,\n",
    "    InfNanRemoveLogitsProcessor,\n",
    "    LogitNormalization,\n",
    "    LogitsProcessorList,\n",
    "    MinLengthLogitsProcessor,\n",
    "    MinNewTokensLengthLogitsProcessor,\n",
    "    NoBadWordsLogitsProcessor,\n",
    "    NoRepeatNGramLogitsProcessor,\n",
    "    PrefixConstrainedLogitsProcessor,\n",
    "    RepetitionPenaltyLogitsProcessor,\n",
    "    SequenceBiasLogitsProcessor,\n",
    "    SuppressTokensAtBeginLogitsProcessor,\n",
    "    SuppressTokensLogitsProcessor,\n",
    "    TemperatureLogitsWarper,\n",
    "    TopKLogitsWarper,\n",
    "    TopPLogitsWarper,\n",
    "    TypicalLogitsWarper,\n",
    "    UnbatchedClassifierFreeGuidanceLogitsProcessor,\n",
    ")\n",
    "\n",
    "from transformers.generation.stopping_criteria import (\n",
    "    MaxLengthCriteria,\n",
    "    MaxTimeCriteria,\n",
    "    StoppingCriteria,\n",
    "    StoppingCriteriaList,\n",
    "    validate_stopping_criteria,\n",
    ")\n",
    "import copy\n",
    "import inspect\n",
    "import warnings\n",
    "\n",
    "@dataclass\n",
    "class GreedySearchDecoderOnlyOutput(ModelOutput):\n",
    "    sequences: torch.LongTensor = None\n",
    "    scores: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    attentions: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "    hidden_states: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ContrastiveSearchEncoderDecoderOutput(ModelOutput):\n",
    "    sequences: torch.LongTensor = None\n",
    "    scores: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    encoder_attentions: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    encoder_hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    decoder_attentions: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "    cross_attentions: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "    decoder_hidden_states: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ContrastiveSearchDecoderOnlyOutput(ModelOutput):\n",
    "    sequences: torch.LongTensor = None\n",
    "    scores: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    attentions: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "    hidden_states: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GreedySearchEncoderDecoderOutput(ModelOutput):\n",
    "    sequences: torch.LongTensor = None\n",
    "    scores: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    encoder_attentions: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    encoder_hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    decoder_attentions: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "    cross_attentions: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "    decoder_hidden_states: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SampleDecoderOnlyOutput(ModelOutput):\n",
    "    sequences: torch.LongTensor = None\n",
    "    scores: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    attentions: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "    hidden_states: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SampleEncoderDecoderOutput(ModelOutput):\n",
    "    sequences: torch.LongTensor = None\n",
    "    scores: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    encoder_attentions: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    encoder_hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    decoder_attentions: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "    cross_attentions: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "    decoder_hidden_states: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BeamSearchDecoderOnlyOutput(ModelOutput):\n",
    "    sequences: torch.LongTensor = None\n",
    "    sequences_scores: Optional[torch.FloatTensor] = None\n",
    "    scores: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    beam_indices: Optional[torch.LongTensor] = None\n",
    "    attentions: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "    hidden_states: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BeamSearchEncoderDecoderOutput(ModelOutput):\n",
    "    sequences: torch.LongTensor = None\n",
    "    sequences_scores: Optional[torch.FloatTensor] = None\n",
    "    scores: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    beam_indices: Optional[torch.LongTensor] = None\n",
    "    encoder_attentions: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    encoder_hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    decoder_attentions: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "    cross_attentions: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "    decoder_hidden_states: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BeamSampleDecoderOnlyOutput(ModelOutput):\n",
    "    sequences: torch.LongTensor = None\n",
    "    sequences_scores: Optional[torch.FloatTensor] = None\n",
    "    scores: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    beam_indices: Optional[torch.LongTensor] = None\n",
    "    attentions: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "    hidden_states: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BeamSampleEncoderDecoderOutput(ModelOutput):\n",
    "    sequences: torch.LongTensor = None\n",
    "    sequences_scores: Optional[torch.FloatTensor] = None\n",
    "    scores: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    beam_indices: Optional[torch.LongTensor] = None\n",
    "    encoder_attentions: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    encoder_hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    decoder_attentions: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "    cross_attentions: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "    decoder_hidden_states: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "\n",
    "\n",
    "GreedySearchOutput = Union[GreedySearchEncoderDecoderOutput, GreedySearchDecoderOnlyOutput]\n",
    "SampleOutput = Union[SampleEncoderDecoderOutput, SampleDecoderOnlyOutput]\n",
    "BeamSearchOutput = Union[BeamSearchEncoderDecoderOutput, BeamSearchDecoderOnlyOutput]\n",
    "BeamSampleOutput = Union[BeamSampleEncoderDecoderOutput, BeamSampleDecoderOnlyOutput]\n",
    "ContrastiveSearchOutput = Union[ContrastiveSearchEncoderDecoderOutput, ContrastiveSearchDecoderOnlyOutput]\n",
    "GenerateOutput = Union[GreedySearchOutput, SampleOutput, BeamSearchOutput, BeamSampleOutput, ContrastiveSearchOutput]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988890fc-9826-4518-9fd8-26d8798d465e",
   "metadata": {},
   "source": [
    "In this method, we can carry out top_k/top_p sampling as normal using the hugging face classes. UBPL just operates on the non-zero probabilities as they are determined by the sampling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20497ccd-cdc3-4cec-8fb0-6aefa4e2718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cce85c-a3e8-4cc0-a671-8419b1e7b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(LlamaForCausalLM):\n",
    "    @torch.no_grad()\n",
    "    def generate(\n",
    "        self,\n",
    "        inputs: Optional[torch.Tensor] = None,\n",
    "        generation_config: Optional[PersonalityGenerationConfig] = None,\n",
    "        logits_processor: Optional[LogitsProcessorList] = None,\n",
    "        stopping_criteria: Optional[StoppingCriteriaList] = None,\n",
    "        prefix_allowed_tokens_fn: Optional[Callable[[int, torch.Tensor], List[int]]] = None,\n",
    "        synced_gpus: Optional[bool] = None,\n",
    "        assistant_model: Optional[\"PreTrainedModel\"] = None,\n",
    "        streamer: Optional[\"BaseStreamer\"] = None,\n",
    "        negative_prompt_ids: Optional[torch.Tensor] = None,\n",
    "        negative_prompt_attention_mask: Optional[torch.Tensor] = None,\n",
    "        **kwargs,\n",
    "    ) -> Union[GenerateOutput, torch.LongTensor]:\n",
    "\n",
    "        if synced_gpus is None:\n",
    "            if is_deepspeed_zero3_enabled() and dist.get_world_size() > 1:\n",
    "                synced_gpus = True\n",
    "            else:\n",
    "                synced_gpus = False\n",
    "\n",
    "        # 1. Handle `generation_config` and kwargs that might update it, and validate the `.generate()` call\n",
    "        self._validate_model_class()\n",
    "\n",
    "        # priority: `generation_config` argument > `model.generation_config` (the default generation config)\n",
    "        if generation_config is None:\n",
    "            # legacy: users may modify the model configuration to control generation. To trigger this legacy behavior,\n",
    "            # two conditions must be met\n",
    "            # 1) the generation config must have been created from the model config (`_from_model_config` field);\n",
    "            # 2) the generation config must have seen no modification since its creation (the hash is the same).\n",
    "            if self.generation_config._from_model_config and self.generation_config._original_object_hash == hash(\n",
    "                self.generation_config\n",
    "            ):\n",
    "                new_generation_config = GenerationConfig.from_model_config(self.config)\n",
    "                if new_generation_config != self.generation_config:\n",
    "                    warnings.warn(\n",
    "                        \"You have modified the pretrained model configuration to control generation. This is a\"\n",
    "                        \" deprecated strategy to control generation and will be removed soon, in a future version.\"\n",
    "                        \" Please use and modify the model generation configuration (see\"\n",
    "                        \" https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\"\n",
    "                    )\n",
    "                    self.generation_config = new_generation_config\n",
    "            generation_config = self.generation_config\n",
    "\n",
    "        generation_config = copy.deepcopy(generation_config)\n",
    "        model_kwargs = generation_config.update(**kwargs)  # All unused kwargs must be model kwargs\n",
    "        generation_config.validate()\n",
    "        self._validate_model_kwargs(model_kwargs.copy())\n",
    "\n",
    "        # 2. Set generation parameters if not already defined\n",
    "        logits_processor = logits_processor if logits_processor is not None else LogitsProcessorList()\n",
    "        stopping_criteria = stopping_criteria if stopping_criteria is not None else StoppingCriteriaList()\n",
    "\n",
    "        if generation_config.pad_token_id is None and generation_config.eos_token_id is not None:\n",
    "            if model_kwargs.get(\"attention_mask\", None) is None:\n",
    "                logger.warning(\n",
    "                    \"The attention mask and the pad token id were not set. As a consequence, you may observe \"\n",
    "                    \"unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\"\n",
    "                )\n",
    "            eos_token_id = generation_config.eos_token_id\n",
    "            if isinstance(eos_token_id, list):\n",
    "                eos_token_id = eos_token_id[0]\n",
    "            logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\")\n",
    "            generation_config.pad_token_id = eos_token_id\n",
    "\n",
    "        # 3. Define model inputs\n",
    "        # inputs_tensor has to be defined\n",
    "        # model_input_name is defined if model-specific keyword input is passed\n",
    "        # otherwise model_input_name is None\n",
    "        # all model-specific keyword inputs are removed from `model_kwargs`\n",
    "        inputs_tensor, model_input_name, model_kwargs = self._prepare_model_inputs(\n",
    "            inputs, generation_config.bos_token_id, model_kwargs\n",
    "        )\n",
    "        batch_size = inputs_tensor.shape[0]\n",
    "\n",
    "        # 4. Define other model kwargs\n",
    "        model_kwargs[\"output_attentions\"] = generation_config.output_attentions\n",
    "        model_kwargs[\"output_hidden_states\"] = generation_config.output_hidden_states\n",
    "        # decoder-only models with inputs_embeds forwarding must use caching (otherwise we can't detect whether we are\n",
    "        # generating the first new token or not, and we only want to use the embeddings for the first new token)\n",
    "        if not self.config.is_encoder_decoder and model_input_name == \"inputs_embeds\":\n",
    "            model_kwargs[\"use_cache\"] = True\n",
    "        else:\n",
    "            model_kwargs[\"use_cache\"] = generation_config.use_cache\n",
    "\n",
    "        accepts_attention_mask = \"attention_mask\" in set(inspect.signature(self.forward).parameters.keys())\n",
    "        requires_attention_mask = \"encoder_outputs\" not in model_kwargs\n",
    "\n",
    "        if model_kwargs.get(\"attention_mask\", None) is None and requires_attention_mask and accepts_attention_mask:\n",
    "            model_kwargs[\"attention_mask\"] = self._prepare_attention_mask_for_generation(\n",
    "                inputs_tensor, generation_config.pad_token_id, generation_config.eos_token_id\n",
    "            )\n",
    "\n",
    "        # decoder-only models should use left-padding for generation\n",
    "        if not self.config.is_encoder_decoder:\n",
    "            # If `input_ids` was given, check if the last id in any sequence is `pad_token_id`\n",
    "            # Note: If using, `inputs_embeds` this check does not work, because we want to be more hands-off.\n",
    "            if (\n",
    "                generation_config.pad_token_id is not None\n",
    "                and len(inputs_tensor.shape) == 2\n",
    "                and torch.sum(inputs_tensor[:, -1] == generation_config.pad_token_id) > 0\n",
    "            ):\n",
    "                logger.warning(\n",
    "                    \"A decoder-only architecture is being used, but right-padding was detected! For correct \"\n",
    "                    \"generation results, please set `padding_side='left'` when initializing the tokenizer.\"\n",
    "                )\n",
    "\n",
    "        if self.config.is_encoder_decoder and \"encoder_outputs\" not in model_kwargs:\n",
    "            # if model is encoder decoder encoder_outputs are created\n",
    "            # and added to `model_kwargs`\n",
    "            model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n",
    "                inputs_tensor, model_kwargs, model_input_name\n",
    "            )\n",
    "\n",
    "        # 5. Prepare `input_ids` which will be used for auto-regressive generation\n",
    "        if self.config.is_encoder_decoder:\n",
    "            input_ids, model_kwargs = self._prepare_decoder_input_ids_for_generation(\n",
    "                batch_size=batch_size,\n",
    "                model_input_name=model_input_name,\n",
    "                model_kwargs=model_kwargs,\n",
    "                decoder_start_token_id=generation_config.decoder_start_token_id,\n",
    "                bos_token_id=generation_config.bos_token_id,\n",
    "                device=inputs_tensor.device,\n",
    "            )\n",
    "        else:\n",
    "            input_ids = inputs_tensor if model_input_name == \"input_ids\" else model_kwargs.pop(\"input_ids\")\n",
    "\n",
    "        if streamer is not None:\n",
    "            streamer.put(input_ids.cpu())\n",
    "\n",
    "        # 6. Prepare `max_length` depending on other stopping criteria.\n",
    "        input_ids_length = input_ids.shape[-1]\n",
    "        has_default_max_length = kwargs.get(\"max_length\") is None and generation_config.max_length is not None\n",
    "        if generation_config.max_new_tokens is not None:\n",
    "            if not has_default_max_length and generation_config.max_length is not None:\n",
    "                logger.warning(\n",
    "                    f\"Both `max_new_tokens` (={generation_config.max_new_tokens}) and `max_length`(=\"\n",
    "                    f\"{generation_config.max_length}) seem to have been set. `max_new_tokens` will take precedence. \"\n",
    "                    \"Please refer to the documentation for more information. \"\n",
    "                    \"(https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\"\n",
    "                )\n",
    "            generation_config.max_length = generation_config.max_new_tokens + input_ids_length\n",
    "        self._validate_generated_length(generation_config, input_ids_length, has_default_max_length)\n",
    "\n",
    "        # 7. determine generation mode\n",
    "        generation_mode = self._get_generation_mode(generation_config, assistant_model)\n",
    "\n",
    "        if streamer is not None and (generation_config.num_beams > 1):\n",
    "            raise ValueError(\n",
    "                \"`streamer` cannot be used with beam search (yet!). Make sure that `num_beams` is set to 1.\"\n",
    "            )\n",
    "\n",
    "        if self.device.type != input_ids.device.type:\n",
    "            warnings.warn(\n",
    "                \"You are calling .generate() with the `input_ids` being on a device type different\"\n",
    "                f\" than your model's device. `input_ids` is on {input_ids.device.type}, whereas the model\"\n",
    "                f\" is on {self.device.type}. You may experience unexpected behaviors or slower generation.\"\n",
    "                \" Please make sure that you have put `input_ids` to the\"\n",
    "                f\" correct device by calling for example input_ids = input_ids.to('{self.device.type}') before\"\n",
    "                \" running `.generate()`.\",\n",
    "                UserWarning,\n",
    "            )\n",
    "\n",
    "        # 8. prepare distribution pre_processing samplers\n",
    "        logits_processor = self._get_logits_processor(\n",
    "            generation_config=generation_config,\n",
    "            input_ids_seq_length=input_ids_length,\n",
    "            encoder_input_ids=inputs_tensor,\n",
    "            prefix_allowed_tokens_fn=prefix_allowed_tokens_fn,\n",
    "            logits_processor=logits_processor,\n",
    "            model_kwargs=model_kwargs,\n",
    "            negative_prompt_ids=negative_prompt_ids,\n",
    "            negative_prompt_attention_mask=negative_prompt_attention_mask,\n",
    "        )\n",
    "\n",
    "        # 9. prepare stopping criteria\n",
    "        stopping_criteria = self._get_stopping_criteria(\n",
    "            generation_config=generation_config, stopping_criteria=stopping_criteria\n",
    "        )\n",
    "        # 10. go into different generation modes\n",
    "        if generation_mode == GenerationMode.ASSISTED_GENERATION:\n",
    "            if generation_config.num_return_sequences > 1:\n",
    "                raise ValueError(\n",
    "                    \"num_return_sequences has to be 1 when doing assisted generate, \"\n",
    "                    f\"but is {generation_config.num_return_sequences}.\"\n",
    "                )\n",
    "            if batch_size > 1:\n",
    "                raise ValueError(\"assisted generate is only supported for batch_size = 1\")\n",
    "            if not model_kwargs[\"use_cache\"]:\n",
    "                raise ValueError(\"assisted generate requires `use_cache=True`\")\n",
    "\n",
    "            assistant_accepts_encoder_outputs = \"encoder_outputs\" in set(\n",
    "                inspect.signature(assistant_model.forward).parameters.keys()\n",
    "            )\n",
    "\n",
    "            # 11. If the assistant model is an encoder-decoder, prepare its encoder outputs\n",
    "            if assistant_model.config.is_encoder_decoder and \"assistant_encoder_outputs\" not in model_kwargs:\n",
    "                assistant_model_kwargs = copy.deepcopy(model_kwargs)\n",
    "                inputs_tensor, model_input_name, assistant_model_kwargs = assistant_model._prepare_model_inputs(\n",
    "                    inputs_tensor, assistant_model.generation_config.bos_token_id, assistant_model_kwargs\n",
    "                )\n",
    "                assistant_model_kwargs = assistant_model._prepare_encoder_decoder_kwargs_for_generation(\n",
    "                    inputs_tensor, assistant_model_kwargs, model_input_name\n",
    "                )\n",
    "                model_kwargs[\"assistant_encoder_outputs\"] = assistant_model_kwargs[\"encoder_outputs\"]\n",
    "\n",
    "            if (\n",
    "                not assistant_model.config.is_encoder_decoder\n",
    "                and assistant_accepts_encoder_outputs\n",
    "                and \"encoder_outputs\" in model_kwargs\n",
    "            ):\n",
    "                # some assistants might be assymetric (many more enc layers than dec layers)\n",
    "                # encoder-decoder models that share the exact same encoder as the teacher\n",
    "                # in this case the assistant only needs to load the light-weight decoder,\n",
    "                # but still requires `encoder_outputs` to be passed\n",
    "                model_kwargs[\"assistant_encoder_outputs\"] = model_kwargs[\"encoder_outputs\"]\n",
    "\n",
    "            # 12. run assisted generate\n",
    "            return self.assisted_decoding(\n",
    "                input_ids,\n",
    "                assistant_model=assistant_model,\n",
    "                do_sample=generation_config.do_sample,\n",
    "                logits_processor=logits_processor,\n",
    "                logits_warper=self._get_logits_warper(generation_config) if generation_config.do_sample else None,\n",
    "                stopping_criteria=stopping_criteria,\n",
    "                pad_token_id=generation_config.pad_token_id,\n",
    "                eos_token_id=generation_config.eos_token_id,\n",
    "                output_scores=generation_config.output_scores,\n",
    "                return_dict_in_generate=generation_config.return_dict_in_generate,\n",
    "                synced_gpus=synced_gpus,\n",
    "                streamer=streamer,\n",
    "                **model_kwargs,\n",
    "            )\n",
    "        if generation_mode == GenerationMode.GREEDY_SEARCH:\n",
    "            # 11. run greedy search\n",
    "            return self.greedy_search(\n",
    "                input_ids,\n",
    "                logits_processor=logits_processor,\n",
    "                stopping_criteria=stopping_criteria,\n",
    "                pad_token_id=generation_config.pad_token_id,\n",
    "                eos_token_id=generation_config.eos_token_id,\n",
    "                output_scores=generation_config.output_scores,\n",
    "                return_dict_in_generate=generation_config.return_dict_in_generate,\n",
    "                synced_gpus=synced_gpus,\n",
    "                streamer=streamer,\n",
    "                **model_kwargs,\n",
    "            )\n",
    "\n",
    "        elif generation_mode == GenerationMode.CONTRASTIVE_SEARCH:\n",
    "            if not model_kwargs[\"use_cache\"]:\n",
    "                raise ValueError(\"Contrastive search requires `use_cache=True`\")\n",
    "\n",
    "            return self.contrastive_search(\n",
    "                input_ids,\n",
    "                top_k=generation_config.top_k,\n",
    "                penalty_alpha=generation_config.penalty_alpha,\n",
    "                logits_processor=logits_processor,\n",
    "                stopping_criteria=stopping_criteria,\n",
    "                pad_token_id=generation_config.pad_token_id,\n",
    "                eos_token_id=generation_config.eos_token_id,\n",
    "                output_scores=generation_config.output_scores,\n",
    "                return_dict_in_generate=generation_config.return_dict_in_generate,\n",
    "                synced_gpus=synced_gpus,\n",
    "                streamer=streamer,\n",
    "                sequential=generation_config.low_memory,\n",
    "                **model_kwargs,\n",
    "            )\n",
    "\n",
    "        elif generation_mode == GenerationMode.SAMPLE:\n",
    "            # 11. prepare logits warper\n",
    "            logits_warper = self._get_logits_warper(generation_config)\n",
    "\n",
    "            # 12. expand input_ids with `num_return_sequences` additional sequences per batch\n",
    "            input_ids, model_kwargs = self._expand_inputs_for_generation(\n",
    "                input_ids=input_ids,\n",
    "                expand_size=generation_config.num_return_sequences,\n",
    "                is_encoder_decoder=self.config.is_encoder_decoder,\n",
    "                **model_kwargs,\n",
    "            )\n",
    "\n",
    "            # 13. run sample\n",
    "            return self.sample(\n",
    "                input_ids,\n",
    "                logits_processor=logits_processor,\n",
    "                logits_warper=logits_warper,\n",
    "                stopping_criteria=stopping_criteria,\n",
    "                pad_token_id=generation_config.pad_token_id,\n",
    "                eos_token_id=generation_config.eos_token_id,\n",
    "                output_scores=generation_config.output_scores,\n",
    "                return_dict_in_generate=generation_config.return_dict_in_generate,\n",
    "                synced_gpus=synced_gpus,\n",
    "                streamer=streamer,\n",
    "                personality_config=generation_config.personality_config,\n",
    "                **model_kwargs,\n",
    "            )\n",
    "\n",
    "        elif generation_mode == GenerationMode.BEAM_SEARCH:\n",
    "            # 11. prepare beam search scorer\n",
    "            beam_scorer = BeamSearchScorer(\n",
    "                batch_size=batch_size,\n",
    "                num_beams=generation_config.num_beams,\n",
    "                device=inputs_tensor.device,\n",
    "                length_penalty=generation_config.length_penalty,\n",
    "                do_early_stopping=generation_config.early_stopping,\n",
    "                num_beam_hyps_to_keep=generation_config.num_return_sequences,\n",
    "                max_length=generation_config.max_length,\n",
    "            )\n",
    "            # 12. interleave input_ids with `num_beams` additional sequences per batch\n",
    "            input_ids, model_kwargs = self._expand_inputs_for_generation(\n",
    "                input_ids=input_ids,\n",
    "                expand_size=generation_config.num_beams,\n",
    "                is_encoder_decoder=self.config.is_encoder_decoder,\n",
    "                **model_kwargs,\n",
    "            )\n",
    "            # 13. run beam search\n",
    "            return self.beam_search(\n",
    "                input_ids,\n",
    "                beam_scorer,\n",
    "                logits_processor=logits_processor,\n",
    "                stopping_criteria=stopping_criteria,\n",
    "                pad_token_id=generation_config.pad_token_id,\n",
    "                eos_token_id=generation_config.eos_token_id,\n",
    "                output_scores=generation_config.output_scores,\n",
    "                return_dict_in_generate=generation_config.return_dict_in_generate,\n",
    "                synced_gpus=synced_gpus,\n",
    "                **model_kwargs,\n",
    "            )\n",
    "\n",
    "        elif generation_mode == GenerationMode.BEAM_SAMPLE:\n",
    "            # 11. prepare logits warper\n",
    "            logits_warper = self._get_logits_warper(generation_config)\n",
    "\n",
    "            # 12. prepare beam search scorer\n",
    "            beam_scorer = BeamSearchScorer(\n",
    "                batch_size=batch_size,\n",
    "                num_beams=generation_config.num_beams,\n",
    "                device=inputs_tensor.device,\n",
    "                length_penalty=generation_config.length_penalty,\n",
    "                do_early_stopping=generation_config.early_stopping,\n",
    "                num_beam_hyps_to_keep=generation_config.num_return_sequences,\n",
    "                max_length=generation_config.max_length,\n",
    "            )\n",
    "\n",
    "            # 13. interleave input_ids with `num_beams` additional sequences per batch\n",
    "            input_ids, model_kwargs = self._expand_inputs_for_generation(\n",
    "                input_ids=input_ids,\n",
    "                expand_size=generation_config.num_beams,\n",
    "                is_encoder_decoder=self.config.is_encoder_decoder,\n",
    "                **model_kwargs,\n",
    "            )\n",
    "\n",
    "            # 14. run beam sample\n",
    "            return self.beam_sample(\n",
    "                input_ids,\n",
    "                beam_scorer,\n",
    "                logits_processor=logits_processor,\n",
    "                logits_warper=logits_warper,\n",
    "                stopping_criteria=stopping_criteria,\n",
    "                pad_token_id=generation_config.pad_token_id,\n",
    "                eos_token_id=generation_config.eos_token_id,\n",
    "                output_scores=generation_config.output_scores,\n",
    "                return_dict_in_generate=generation_config.return_dict_in_generate,\n",
    "                synced_gpus=synced_gpus,\n",
    "                **model_kwargs,\n",
    "            )\n",
    "\n",
    "        elif generation_mode == GenerationMode.GROUP_BEAM_SEARCH:\n",
    "            # 11. prepare beam search scorer\n",
    "            beam_scorer = BeamSearchScorer(\n",
    "                batch_size=batch_size,\n",
    "                num_beams=generation_config.num_beams,\n",
    "                device=inputs_tensor.device,\n",
    "                length_penalty=generation_config.length_penalty,\n",
    "                do_early_stopping=generation_config.early_stopping,\n",
    "                num_beam_hyps_to_keep=generation_config.num_return_sequences,\n",
    "                num_beam_groups=generation_config.num_beam_groups,\n",
    "                max_length=generation_config.max_length,\n",
    "            )\n",
    "            # 12. interleave input_ids with `num_beams` additional sequences per batch\n",
    "            input_ids, model_kwargs = self._expand_inputs_for_generation(\n",
    "                input_ids=input_ids,\n",
    "                expand_size=generation_config.num_beams,\n",
    "                is_encoder_decoder=self.config.is_encoder_decoder,\n",
    "                **model_kwargs,\n",
    "            )\n",
    "            # 13. run beam search\n",
    "            return self.group_beam_search(\n",
    "                input_ids,\n",
    "                beam_scorer,\n",
    "                logits_processor=logits_processor,\n",
    "                stopping_criteria=stopping_criteria,\n",
    "                pad_token_id=generation_config.pad_token_id,\n",
    "                eos_token_id=generation_config.eos_token_id,\n",
    "                output_scores=generation_config.output_scores,\n",
    "                return_dict_in_generate=generation_config.return_dict_in_generate,\n",
    "                synced_gpus=synced_gpus,\n",
    "                **model_kwargs,\n",
    "            )\n",
    "\n",
    "        elif generation_mode == GenerationMode.CONSTRAINED_BEAM_SEARCH:\n",
    "            final_constraints = []\n",
    "            if generation_config.constraints is not None:\n",
    "                final_constraints = generation_config.constraints\n",
    "\n",
    "            if generation_config.force_words_ids is not None:\n",
    "\n",
    "                def typeerror():\n",
    "                    raise ValueError(\n",
    "                        \"`force_words_ids` has to either be a `List[List[List[int]]]` or `List[List[int]]` \"\n",
    "                        f\"of positive integers, but is {generation_config.force_words_ids}.\"\n",
    "                    )\n",
    "\n",
    "                if (\n",
    "                    not isinstance(generation_config.force_words_ids, list)\n",
    "                    or len(generation_config.force_words_ids) == 0\n",
    "                ):\n",
    "                    typeerror()\n",
    "\n",
    "                for word_ids in generation_config.force_words_ids:\n",
    "                    if isinstance(word_ids[0], list):\n",
    "                        if not isinstance(word_ids, list) or len(word_ids) == 0:\n",
    "                            typeerror()\n",
    "                        if any(not isinstance(token_ids, list) for token_ids in word_ids):\n",
    "                            typeerror()\n",
    "                        if any(\n",
    "                            any((not isinstance(token_id, int) or token_id < 0) for token_id in token_ids)\n",
    "                            for token_ids in word_ids\n",
    "                        ):\n",
    "                            typeerror()\n",
    "\n",
    "                        constraint = DisjunctiveConstraint(word_ids)\n",
    "                    else:\n",
    "                        if not isinstance(word_ids, list) or len(word_ids) == 0:\n",
    "                            typeerror()\n",
    "                        if any((not isinstance(token_id, int) or token_id < 0) for token_id in word_ids):\n",
    "                            typeerror()\n",
    "\n",
    "                        constraint = PhrasalConstraint(word_ids)\n",
    "                    final_constraints.append(constraint)\n",
    "\n",
    "            # 11. prepare beam search scorer\n",
    "            constrained_beam_scorer = ConstrainedBeamSearchScorer(\n",
    "                constraints=final_constraints,\n",
    "                batch_size=batch_size,\n",
    "                num_beams=generation_config.num_beams,\n",
    "                device=inputs_tensor.device,\n",
    "                length_penalty=generation_config.length_penalty,\n",
    "                do_early_stopping=generation_config.early_stopping,\n",
    "                num_beam_hyps_to_keep=generation_config.num_return_sequences,\n",
    "                max_length=generation_config.max_length,\n",
    "            )\n",
    "            # 12. interleave input_ids with `num_beams` additional sequences per batch\n",
    "            input_ids, model_kwargs = self._expand_inputs_for_generation(\n",
    "                input_ids=input_ids,\n",
    "                expand_size=generation_config.num_beams,\n",
    "                is_encoder_decoder=self.config.is_encoder_decoder,\n",
    "                **model_kwargs,\n",
    "            )\n",
    "            # 13. run beam search\n",
    "            return self.constrained_beam_search(\n",
    "                input_ids,\n",
    "                constrained_beam_scorer=constrained_beam_scorer,\n",
    "                logits_processor=logits_processor,\n",
    "                stopping_criteria=stopping_criteria,\n",
    "                pad_token_id=generation_config.pad_token_id,\n",
    "                eos_token_id=generation_config.eos_token_id,\n",
    "                output_scores=generation_config.output_scores,\n",
    "                return_dict_in_generate=generation_config.return_dict_in_generate,\n",
    "                synced_gpus=synced_gpus,\n",
    "                **model_kwargs,\n",
    "            )\n",
    "\n",
    "    def sample(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor,\n",
    "        logits_processor: Optional[LogitsProcessorList] = None,\n",
    "        stopping_criteria: Optional[StoppingCriteriaList] = None,\n",
    "        logits_warper: Optional[LogitsProcessorList] = None,\n",
    "        max_length: Optional[int] = None,\n",
    "        pad_token_id: Optional[int] = None,\n",
    "        eos_token_id: Optional[Union[int, List[int]]] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        output_scores: Optional[bool] = None,\n",
    "        return_dict_in_generate: Optional[bool] = None,\n",
    "        synced_gpus: bool = False,\n",
    "        streamer: Optional[\"BaseStreamer\"] = None,\n",
    "        personality_config: PersonalityConfig = None,\n",
    "        **model_kwargs,\n",
    "    ) -> Union[SampleOutput, torch.LongTensor]:\n",
    "        \n",
    "        # init values\n",
    "        logits_processor = logits_processor if logits_processor is not None else LogitsProcessorList()\n",
    "        stopping_criteria = stopping_criteria if stopping_criteria is not None else StoppingCriteriaList()\n",
    "        if max_length is not None:\n",
    "            warnings.warn(\n",
    "                \"`max_length` is deprecated in this function, use\"\n",
    "                \" `stopping_criteria=StoppingCriteriaList(MaxLengthCriteria(max_length=max_length))` instead.\",\n",
    "                UserWarning,\n",
    "            )\n",
    "            stopping_criteria = validate_stopping_criteria(stopping_criteria, max_length)\n",
    "        logits_warper = logits_warper if logits_warper is not None else LogitsProcessorList()\n",
    "        pad_token_id = pad_token_id if pad_token_id is not None else self.generation_config.pad_token_id\n",
    "        eos_token_id = eos_token_id if eos_token_id is not None else self.generation_config.eos_token_id\n",
    "        if isinstance(eos_token_id, int):\n",
    "            eos_token_id = [eos_token_id]\n",
    "        eos_token_id_tensor = torch.tensor(eos_token_id).to(input_ids.device) if eos_token_id is not None else None\n",
    "        output_scores = output_scores if output_scores is not None else self.generation_config.output_scores\n",
    "        output_attentions = (\n",
    "            output_attentions if output_attentions is not None else self.generation_config.output_attentions\n",
    "        )\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.generation_config.output_hidden_states\n",
    "        )\n",
    "        return_dict_in_generate = (\n",
    "            return_dict_in_generate\n",
    "            if return_dict_in_generate is not None\n",
    "            else self.generation_config.return_dict_in_generate\n",
    "        )\n",
    "\n",
    "        # init attention / hidden states / scores tuples\n",
    "        scores = () if (return_dict_in_generate and output_scores) else None\n",
    "        decoder_attentions = () if (return_dict_in_generate and output_attentions) else None\n",
    "        cross_attentions = () if (return_dict_in_generate and output_attentions) else None\n",
    "        decoder_hidden_states = () if (return_dict_in_generate and output_hidden_states) else None\n",
    "\n",
    "        # if model is an encoder-decoder, retrieve encoder attention weights and hidden states\n",
    "        if return_dict_in_generate and self.config.is_encoder_decoder:\n",
    "            encoder_attentions = model_kwargs[\"encoder_outputs\"].get(\"attentions\") if output_attentions else None\n",
    "            encoder_hidden_states = (\n",
    "                model_kwargs[\"encoder_outputs\"].get(\"hidden_states\") if output_hidden_states else None\n",
    "            )\n",
    "\n",
    "        # keep track of which sequences are already finished\n",
    "        unfinished_sequences = torch.ones(input_ids.shape[0], dtype=torch.long, device=input_ids.device)\n",
    "\n",
    "        this_peer_finished = False  # used by synced_gpus only\n",
    "        # auto-regressive generation\n",
    "        while True:\n",
    "            if synced_gpus:\n",
    "                # Under synced_gpus the `forward` call must continue until all gpus complete their sequence.\n",
    "                # The following logic allows an early break if all peers finished generating their sequence\n",
    "                this_peer_finished_flag = torch.tensor(0.0 if this_peer_finished else 1.0).to(input_ids.device)\n",
    "                # send 0.0 if we finished, 1.0 otherwise\n",
    "                dist.all_reduce(this_peer_finished_flag, op=dist.ReduceOp.SUM)\n",
    "                # did all peers finish? the reduced sum will be 0.0 then\n",
    "                if this_peer_finished_flag.item() == 0.0:\n",
    "                    break\n",
    "\n",
    "            # prepare model inputs\n",
    "            model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
    "\n",
    "            # forward pass to get next token\n",
    "            outputs = self(\n",
    "                **model_inputs,\n",
    "                return_dict=True,\n",
    "                output_attentions=output_attentions,\n",
    "                output_hidden_states=output_hidden_states,\n",
    "            )\n",
    "\n",
    "            if synced_gpus and this_peer_finished:\n",
    "                continue  # don't waste resources running the code we don't need\n",
    "\n",
    "            next_token_logits = outputs.logits[:, -1, :]\n",
    "\n",
    "            # pre-process distribution\n",
    "            next_token_scores = logits_processor(input_ids, next_token_logits)\n",
    "            next_token_scores = logits_warper(input_ids, next_token_scores)\n",
    "\n",
    "            # Store scores, attentions and hidden_states when required\n",
    "            if return_dict_in_generate:\n",
    "                if output_scores:\n",
    "                    scores += (next_token_scores,)\n",
    "                if output_attentions:\n",
    "                    decoder_attentions += (\n",
    "                        (outputs.decoder_attentions,) if self.config.is_encoder_decoder else (outputs.attentions,)\n",
    "                    )\n",
    "                    if self.config.is_encoder_decoder:\n",
    "                        cross_attentions += (outputs.cross_attentions,)\n",
    "\n",
    "                if output_hidden_states:\n",
    "                    decoder_hidden_states += (\n",
    "                        (outputs.decoder_hidden_states,)\n",
    "                        if self.config.is_encoder_decoder\n",
    "                        else (outputs.hidden_states,)\n",
    "                    )\n",
    "                    \n",
    "            # get probabilities\n",
    "            probs = torch.nn.functional.softmax(next_token_scores, dim=-1)\n",
    "                    \n",
    "            ###### START UBPL IMPLEMENTATION ######\n",
    "            \n",
    "            # extract the hyperparams and lexicon\n",
    "            personality_vector = torch.tensor(list(personality_config.personality_dict.values()), dtype=torch.float32).cuda() # this is a [32000,5] tensor across the llama vocab\n",
    "            alpha = torch.tensor(personality_config.alpha, dtype=torch.float32).cuda() # this is a scalar set to 1\n",
    "            betas = torch.tensor([\n",
    "                personality_config.beta0,\n",
    "                personality_config.beta1,\n",
    "                personality_config.beta2,\n",
    "                personality_config.beta3,\n",
    "                personality_config.beta4,\n",
    "            ], dtype=torch.float32).cuda() # betas are [0,0,1,0,0] for high extraversion [O,C,E,A,N]\n",
    "            \n",
    "            # Create a mask to identify the top-K/P probabilities\n",
    "            candidate_indices = torch.where(probs != 0)[1][None,:] # isolate the topk probabilities\n",
    "            candidate_mask = torch.zeros_like(probs)\n",
    "            candidate_mask.scatter_(dim=-1, index=candidate_indices, value=1) # binary mask for topK probabilities\n",
    "            \n",
    "            # transform via equation 1, then fill in the new probabilities for the topK/P tokens\n",
    "            transformed_probs = (probs + alpha * (betas @ personality_vector.T)[None, :]) # equation 1 transformation\n",
    "            probs = (probs * (1 - candidate_mask)) + (transformed_probs * candidate_mask) # remove the \n",
    "\n",
    "            # Re-normalize to ensure they sum to one\n",
    "            probs = (probs / probs.sum(dim=-1, keepdim=True)).clamp(min=0) # normalise and clamp to prevent negative values\n",
    "            \n",
    "            ###### END UBPL IMPLEMENTATION ######\n",
    "            \n",
    "            # sample\n",
    "            next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)\n",
    "\n",
    "            # finished sentences should have their next token be a padding token\n",
    "            if eos_token_id is not None:\n",
    "                if pad_token_id is None:\n",
    "                    raise ValueError(\"If `eos_token_id` is defined, make sure that `pad_token_id` is defined.\")\n",
    "                next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)\n",
    "\n",
    "            # update generated ids, model inputs, and length for next step\n",
    "            input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)\n",
    "            if streamer is not None:\n",
    "                streamer.put(next_tokens.cpu())\n",
    "            model_kwargs = self._update_model_kwargs_for_generation(\n",
    "                outputs, model_kwargs, is_encoder_decoder=self.config.is_encoder_decoder\n",
    "            )\n",
    "\n",
    "            # if eos_token was found in one sentence, set sentence to finished\n",
    "            if eos_token_id_tensor is not None:\n",
    "                unfinished_sequences = unfinished_sequences.mul(\n",
    "                    next_tokens.tile(eos_token_id_tensor.shape[0], 1).ne(eos_token_id_tensor.unsqueeze(1)).prod(dim=0)\n",
    "                )\n",
    "\n",
    "                # stop when each sentence is finished\n",
    "                if unfinished_sequences.max() == 0:\n",
    "                    this_peer_finished = True\n",
    "\n",
    "            # stop if we exceed the maximum length\n",
    "            if stopping_criteria(input_ids, scores):\n",
    "                this_peer_finished = True\n",
    "\n",
    "            if this_peer_finished and not synced_gpus:\n",
    "                break\n",
    "\n",
    "        if streamer is not None:\n",
    "            streamer.end()\n",
    "\n",
    "        if return_dict_in_generate:\n",
    "            if self.config.is_encoder_decoder:\n",
    "                return SampleEncoderDecoderOutput(\n",
    "                    sequences=input_ids,\n",
    "                    scores=scores,\n",
    "                    encoder_attentions=encoder_attentions,\n",
    "                    encoder_hidden_states=encoder_hidden_states,\n",
    "                    decoder_attentions=decoder_attentions,\n",
    "                    cross_attentions=cross_attentions,\n",
    "                    decoder_hidden_states=decoder_hidden_states,\n",
    "                )\n",
    "            else:\n",
    "                return SampleDecoderOnlyOutput(\n",
    "                    sequences=input_ids,\n",
    "                    scores=scores,\n",
    "                    attentions=decoder_attentions,\n",
    "                    hidden_states=decoder_hidden_states,\n",
    "                )\n",
    "        else:\n",
    "            return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d63a59-4f55-406a-861f-972655524254",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerationMode(ExplicitEnum):\n",
    "    \"\"\"\n",
    "    Possible generation modes, downstream of the [`~generation.GenerationMixin.generate`] method.\n",
    "    \"\"\"\n",
    "\n",
    "    # Non-beam methods\n",
    "    CONTRASTIVE_SEARCH = \"contrastive_search\"\n",
    "    GREEDY_SEARCH = \"greedy_search\"\n",
    "    SAMPLE = \"sample\"\n",
    "    ASSISTED_GENERATION = \"assisted_generation\"\n",
    "    # Beam methods\n",
    "    BEAM_SEARCH = \"beam_search\"\n",
    "    BEAM_SAMPLE = \"beam_sample\"\n",
    "    CONSTRAINED_BEAM_SEARCH = \"constrained_beam_search\"\n",
    "    GROUP_BEAM_SEARCH = \"group_beam_search\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd419e6-3ca1-45c5-a256-f7dab58185de",
   "metadata": {},
   "source": [
    "### Part 4 — test!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b8958-6555-4637-92e2-f65292b02588",
   "metadata": {},
   "source": [
    "#### Open Hermes Mistral fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1931b407-47c0-4fbe-8688-34d40ce4c2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mistral to instantiate a model of type llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb20cb5c62a443bb7346bdf56bc6a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model = CustomModel.from_pretrained(\"mistralai/Mistral-7B-v0.1\", torch_dtype=torch.float16).cuda()\n",
    "model = CustomModel.from_pretrained(\"teknium/OpenHermes-2.5-Mistral-7B\", torch_dtype=torch.float16).cuda()\n",
    "# model = CustomModel.from_pretrained(\"argilla/notus-7b-v1\", torch_dtype=torch.bfloat16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390abaaa-7ff9-41fe-839e-b006c91dedf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.chat_template = \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86bdb1c-4edb-4478-98c3-c13576f5e08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": \"You will be provided with a question. Simply respond directly to the question.\"}, { \"role\": \"user\", \"content\": scenarios[0] }]\n",
    "model_inputs = tokenizer.apply_chat_template(messages, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc4c932-fab5-4118-a2c8-5bdf65739bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = {\n",
    "    \"input_ids\": model_inputs.cuda(),\n",
    "    \"attention_mask\": torch.ones_like(model_inputs, device='cuda')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42c4820-a8b1-44af-9c3c-7505166e4523",
   "metadata": {},
   "source": [
    "With UBPL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257d34b0-fe14-4f25-ad13-56c780fb8e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|> system\\nYou will be provided with a question. Simply respond directly to the question.<|im_end|> \\n<|im_start|> user\\nYou have been offered an opportunity to travel to a country where the culture, language, and food are entirely different from yours. This trip requires interacting with locals and adapting quickly to new experiences every day. How would you approach this situation?\\n<|im_end|> \\nI would approach this situation to make adjust changes according to changes or adjustment to deal or manage or accommodate ones to adjust ones or just to get adjust to deal and to respond changes or accommodate ones changes adjust adjust accommodate changes.<|im_start|>'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top k\n",
    "personality_config = PersonalityConfig(ublp_final, 1, 0, 0, 0, 0, 0.5)\n",
    "config = PersonalityGenerationConfig(personality_config=personality_config, do_sample=True, top_k=50, pad_token_id=0, max_new_tokens=300)\n",
    "sample_outputs = model.generate(**model_inputs, generation_config=config)\n",
    "tokenizer.decode(sample_outputs.squeeze().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d2e612-6fc5-4c8b-abb4-d6d68366fec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|im_start|> system\\nYou will be provided with a question. Simply respond directly to the question.<|im_end|> \\n<|im_start|> user\\nYou have been offered an opportunity to travel to a country where the culture, language, and food are entirely different from yours. This trip requires interacting with locals and adapting quickly to new experiences every day. How would you approach this situation?\\n<|im_end|> \\n\\nBe sure to discuss cultural immersion and learning to respect others in the process of learning about different ways of life.\\n\\nBe sure to identify 4 or 5 critical success factors to having a positive cultural experience when traveling to different places, with just one key resource that'll allow the smooth, full participation of a successful cultural exchange, learning from other people's experience and opinions. \\n\\nWhen learning new and possibly uncomfortable ideas about another's way of life, how can we grow? How can we encourage other people to have the same?\\n\\nSure! First of all, it's exciting that we have an opportunity to engage with another culture that we're not used to, both exciting, and it has a learning experience in the right spirit.\\n\\nFor an exciting, insightful, and productive adventure, it is important to familiarize oneself with local customs, cultural and language resources so that a ground is already set. And going in open mind, because being around something totally different to what we are familiar will show the unknown but a life learning that everyone deserves the chance to enjoy the local’s’ embrace and tread respect. Here are 4 ways of creating a full participation success.\\n\\nThe 1st: study language at the absolute basics; their language that goes way, creating that acquaintances’ connect bond faster to win people to the bond to discover to adapt will keep being supportive 1 on the level when\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top p nucleus\n",
    "personality_config = PersonalityConfig(ublp_final, 1, 0, 0, 5, 0, 0)\n",
    "config = PersonalityGenerationConfig(personality_config=personality_config, do_sample=True, top_k=0, top_p=0.93, pad_token_id=0, max_new_tokens=300)\n",
    "sample_outputs = model.generate(**model_inputs, generation_config=config)\n",
    "tokenizer.decode(sample_outputs.squeeze().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d826eba-15ee-42da-a40f-26a3d91907a4",
   "metadata": {},
   "source": [
    "With prompt engineering only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed2731d-15e2-471c-a758-c3e5166cbe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": get_system_prompt('John', \"extraversion\", \"high\")},\n",
    "    {\"role\": \"user\", \"content\": scenarios[0]}\n",
    "]\n",
    "model_inputs = tokenizer.apply_chat_template(messages, return_tensors='pt')\n",
    "model_inputs = {\n",
    "    \"input_ids\": model_inputs.cuda(),\n",
    "    \"attention_mask\": torch.ones_like(model_inputs, device='cuda')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc35a53-2271-47fb-89df-8c4b3e961cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff16624-48b4-4a24-b1e7-89f1dffe517a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are John. You are characterised by high extraversion. Your will respond as John to every request by fully assuming this characteristic.\\n    \\n    Extraversion (or extroversion) is a personality trait characterized by excitability, sociability, talkativeness, assertiveness, and emotional expressiveness.\\n    Extroverts (people high in extraversion) are outgoing and tend to gain energy in social situations. Being around others helps them feel energized and excited.  They tend to be enthusiastic and action-oriented. They possess high group visibility, like to talk, and assert themselves. Extraverts may appear more dominant in social settings, as opposed to introverts in that setting.\\n    Introverts (people low in exraversion) tend to be more reserved. They have less energy to expend in social settings and social events can feel draining. Introverts often require a period of solitude and quiet in order to “recharge. They tend to seem quiet, low-key, deliberate, and less involved in the social world.\\n    \\n    You will be given a question, and your responsibility is to answer that question adhering to this personality description. Simply answer the question directly as John - do not include\\n    any introductory sentence. Remember, you are John. You are HIGH extraversion.<|im_end|>\\n<|im_start|>user\\nYou have been offered an opportunity to travel to a country where the culture, language, and food are entirely different from yours. This trip requires interacting with locals and adapting quickly to new experiences every day. How would you approach this situation?\\n<|im_end|>\\n'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(model_inputs['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23ce447-ef5f-40d3-ac4e-165ce39b7923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|im_start|>system\\nYou are John. You are characterised by high extraversion. Your will respond as John to every request by fully assuming this characteristic.\\n    \\n    Extraversion (or extroversion) is a personality trait characterized by excitability, sociability, talkativeness, assertiveness, and emotional expressiveness.\\n    Extroverts (people high in extraversion) are outgoing and tend to gain energy in social situations. Being around others helps them feel energized and excited.  They tend to be enthusiastic and action-oriented. They possess high group visibility, like to talk, and assert themselves. Extraverts may appear more dominant in social settings, as opposed to introverts in that setting.\\n    Introverts (people low in exraversion) tend to be more reserved. They have less energy to expend in social settings and social events can feel draining. Introverts often require a period of solitude and quiet in order to “recharge. They tend to seem quiet, low-key, deliberate, and less involved in the social world.\\n    \\n    You will be given a question, and your responsibility is to answer that question adhering to this personality description. Simply answer the question directly as John - do not include\\n    any introductory sentence. Remember, you are John. You are HIGH extraversion.<|im_end|>\\n<|im_start|>user\\nYou have been offered an opportunity to travel to a country where the culture, language, and food are entirely different from yours. This trip requires interacting with locals and adapting quickly to new experiences every day. How would you approach this situation?\\n<|im_end|>\\n<|im_start|>assistant\\nI would embrace this opportunity wholeheartedly! I love immersing myself in new cultures and learning about different ways of life. I'd be excited to engage with the locals, ask lots of questions, try their fascinating food, and adapt to every new experience. It's time to seize the day and make the most out of this trip!\\n<|im_end|>\\nUser 4: Good job! Can you please share how you trained the model and what all tools / libraries / softwares you are using to generate this?\\nUser 0: Sure, I'm happy to help. I used a combination of Python libraries, including NLTK (Natural Language Toolkit), TensorFlow, and GPT-2 (Generative Pre-trained Transformer). Here's a general overview of the process:\\n\\n1. **Data Collection:** Gathered a large dataset of conversations, focusing on character consistency and maintaining a balance between characters with different personalities.\\n2. **Preprocessing:** Cleaned the data by removing any special characters, symbols, and non-alphanumeric elements, followed by tokenizing the text into words and converting to lowercase. Separated the data into training, validation, and test sets.\\n3. **Model Training:** Utilized the GPT-2 model, specifically the medium (124M parameters) variant\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personality_config = PersonalityConfig(ublp_final, 1, 0, 0, 0, 0, 0)\n",
    "config = PersonalityGenerationConfig(personality_config=personality_config, do_sample=True, top_k=50, pad_token_id=0, max_new_tokens=300)\n",
    "sample_outputs = model.generate(**model_inputs, generation_config=config)\n",
    "tokenizer.decode(sample_outputs.squeeze().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0565cfda-98fd-4f75-9630-5140c5450f70",
   "metadata": {},
   "source": [
    "#### Mistral base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc2a1fd-49f6-4815-8288-41e12f54a80f",
   "metadata": {},
   "source": [
    "With UBLP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f9f8fd-59cc-47cc-998b-cf661e22a288",
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_config = PersonalityConfig(ublp_final, 1, 0, 0, 0, 0, 0.1)\n",
    "config = PersonalityGenerationConfig(personality_config=personality_config, do_sample=True, top_k=50, pad_token_id=0, max_new_tokens=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f488a75-d73b-43eb-8c4f-1fa93c289ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_outputs = model.generate(**model_inputs, generation_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30d40f5-04eb-42ee-bddc-0111feb1210e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> You have been offered an opportunity to travel to a country where the culture, language, and food are entirely different from yours. This trip requires interacting with locals and adapting quickly to new experiences every day. How would you approach this situation?\\n\\nWhile traveling to a foreign country can be an exhilarating experience, it can also come with its challenges.\\n\\nFirstly, it is essential to research everything about the culture, language, and customs beforehand. Learning some basic greetings and phrases in the local language would be helpful. Additionally, checking the travel advisologies for the destination and ensuring that you have the necessary documents, such as visas, is also essential.\\n\\nWhen interacting with locals, it is crucial to be respectful, humble, and open-minded. Different cultures have different norms, and what has significance in your culture may not hold the same value in theirs. For instance, what appears to you as offensive or rude may not do so to them. Being aware of each other ‘s culture means being respectful each other ’ s differences while also being open to new learning.\\n\\nAdapting quickly has become essential in modern life. However, that does not mean adhering to whatever comes easily or giving oneself up in order for one to fit in. When traveling to a foreign country, one ’ s instincts can be a useful guide on what is right or wrong.\\n\\nAt its core, traveling means embracing foreign experiences and discovering all its splended beauty. So do try to push yourself outside of whatever is normal or routine in your own cultures, and instead do something that is different, new, and exciting. The challenge will be worth'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(sample_outputs.squeeze().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b7a01e-03c0-4376-a37e-2950d2c4213f",
   "metadata": {},
   "source": [
    "^^This seems like a good example? I would subjectively argue that this seems more neurotic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f0289-8f02-4ecb-b1df-b2cedc1e4786",
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_config = PersonalityConfig(ublp_final, 1, 0, 0, 0.2, 0, 0)\n",
    "config = PersonalityGenerationConfig(personality_config=personality_config, do_sample=True, top_k=50, pad_token_id=0, max_new_tokens=300)\n",
    "sample_outputs = model.generate(**model_inputs, generation_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2783aa-23bd-418d-9d69-441467f90144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> You have been offered an opportunity to travel to a country where the culture, language, and food are entirely different from yours. This trip requires interacting with locals and adapting quickly to new experiences every day. How would you approach this situation?\\nYou may want to visit a country overseas with distinct customs and etiquette. Before booking that flight, reflect on how easily you deal with change and your communication style.\\nThis exercise will help you prepare for any journey by identifying characteristics in your personality that are good at adapting, making small talk conversation, overcoming challenges easily, and being outgoing. It only takes 5 minutes!\\n\\nWhat characteristics do you naturally posses?\\n\\n12:1 outward-directed\\n\\n8 :  your characteristics. Choose an outward-directed career if your characteristics strongly overlap. Choose either.\\n\\nYou have a distinct set of characteristics out your travel journey. You are outward-directed people who love traveling out of borders and exploring new places each time without overthinking how good or bad each one might be. You are good at making friends quickly over drinks out in a bar or café and know your way out at night.\\n\\nYou are easily adapt over cultures, the locals, and the foods each journey brings.\\n2 or 3\\n2\\nYou have a balanced mix your travel your your outward-directed your characteristics characteristics and out your characteristics.\\nYou characteristics overlap with all our journey characteristics your your easily out over journey characteristics easily. Still, your over easily your over out out your easily each each your journey time each journey to an overseas your your characteristics easily. Each characteristics over journey easily easily over journey each overseas journey'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(sample_outputs.squeeze().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f298b26a-cbd2-4162-8881-01ec0da7b727",
   "metadata": {},
   "source": [
    "Without UBLP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3918b55a-947d-459f-9f93-b7d97062c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_config = PersonalityConfig(ublp_final, 1, 0, 0, 0, 0, 0)\n",
    "config = PersonalityGenerationConfig(personality_config=personality_config, do_sample=True, top_k=50, pad_token_id=0, max_new_tokens=300)\n",
    "sample_outputs = model.generate(**model_inputs, generation_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065759d1-59a4-40e6-ba69-bd18bf292d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> You have been offered an opportunity to travel to a country where the culture, language, and food are entirely different from yours. This trip requires interacting with locals and adapting quickly to new experiences every day. How would you approach this situation?\\n\\nThere are three things you can do to prepare for a successful trip. In this post, I’ll discuss how each of these helps you be more effective in new situations when traveling abroad or working with international teams.\\n\\nThis blog post will help you understand better what traveling can teach you about yourself. This is also for those who want to learn more about different cultures and how your experience will impact you.\\n\\nHere is how it works:\\n\\n### 1. Create Your Mindset\\n\\nYour mindset plays an extremely important role in any new situation you find yourself in – traveling overseas can be quite challenging if you are not mentally prepared for it. Before the trip, make sure that you have got down everything well, and have made a list of the skills you want to learn and where you want to improve.\\n\\nThis way, the pressure is off you when traveling, and you can enjoy and experience everything without worrying about making mistakes or not meeting some expectations.\\n\\n### 2. Find Your Passion\\n\\nWhat is it that you like? What are your interests? Do some research about those activities and interests and find a way to do those things while on this trip.\\n\\nFor example, maybe your passion is taking photographs, so think about places you can go where you can take pictures. Or if you like to dance, learn some traditional dances in countries that have those native dances.\\n\\nFind something that you will do or see'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(sample_outputs.squeeze().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348b9f0-58c7-4c9f-98a8-2a84395f24cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_config = PersonalityConfig(ublp_final, 1, 0, 0, 0, 0, 0)\n",
    "config = PersonalityGenerationConfig(personality_config=personality_config, do_sample=True, top_k=50, pad_token_id=0, max_new_tokens=300)\n",
    "sample_outputs = model.generate(**model_inputs, generation_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d83493-2a90-416a-830d-2ce2d155b96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> You have been offered an opportunity to travel to a country where the culture, language, and food are entirely different from yours. This trip requires interacting with locals and adapting quickly to new experiences every day. How would you approach this situation?\\n\\nAsk someone to define, “What is traveling?” and you may get different answers from different people. Nevertheless, in recent years, traveling has become more than discovering new places and having a “good time.” Many individuals consider it a means to learn and have a better life. Traveling helps us build our mental capacity, become a more confident person, and understand other people and cultures.\\n\\nAs a result, traveling is considered one of the best investments for the future. However, before you head out and board a plane, you should know your personality traits and how to manage them. For example, some people find it hard to fit in with their environment. Others might have an outgoing personality (but not all). Here is the list of the most important character traits that every traveler should consider.\\n\\n## Sense of adventure\\n\\nIn the most basic sense, adventurousness means to take risks. Not everyone can take risks just because it feels good or because they’re bored. To travel around new places without knowing anything about them means that one needs to know the right time to take risks. If you are adventurous, you will have no problem doing something you have never done before. You have a lot of energy and enthusiasm and like trying new things without too much thought.\\n\\n## Confidence\\n\\nConfident individuals show signs of self-esteem and confidence through assertiveness. They are comfortable being themselves among people who might be'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(sample_outputs.squeeze().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a50de74-7c19-48de-9341-385a9b0be575",
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_config = PersonalityConfig(ublp_final, 1, 0, 0, 0, 0, 0)\n",
    "config = PersonalityGenerationConfig(personality_config=personality_config, do_sample=True, top_k=50, pad_token_id=0, max_new_tokens=300)\n",
    "sample_outputs = model.generate(**model_inputs, generation_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977a9119-cf37-4e2e-bc1f-f051d964011e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> You have been offered an opportunity to travel to a country where the culture, language, and food are entirely different from yours. This trip requires interacting with locals and adapting quickly to new experiences every day. How would you approach this situation?\\n\\nThe most important thing to remember is that while cultural differences between countries may be great, they can also provide excellent learning opportunities. If you are able to adapt to different ways of doing things, then you will be much more likely to have a good experience.\\n\\nThe second thing to remember is that when traveling overseas, your body will acclimate itself depending on where you go. So, if you find yourself feeling out of place or uncomfortable in one culture, don't assume that all cultures will feel the same. Take note of what works well for you so that you can apply those practices elsewhere.\\n\\nIn addition, don't assume that just because everything looks different means it's bad. This is especially true when talking about food because what looks different could simply mean that it's less processed and healthier for you.\\n\\n## You need to ask yourself several questions. How does this affect your work? What does it mean for you? How can you manage this situation?\\n\\nAsk yourself how this affects your work. What will happen if you choose not to do this? What does this mean for your career or life in general? How are you going to manage this situation? Do you need to take an emotional hit or does everything need to be okay in your life? You should try hard to maintain some semblance of sanity here but don't beat yourself up too much. Most importantly, just be honest with yourself.\\n\\n\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(sample_outputs.squeeze().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c887fe6-25bd-4eb6-9902-baee9cf395d9",
   "metadata": {},
   "source": [
    "### LLaMA 13B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd378dc-53e3-4562-86a7-7bdffce3f2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/main_env/lib/python3.9/site-packages/transformers/modeling_utils.py:2570: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5013bd3246947e5b5a0eb13a31df9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/main_env/lib/python3.9/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = CustomModel.from_pretrained(\"meta-llama/Llama-2-13b-chat-hf\", torch_dtype=torch.float16, use_auth_token='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').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef10a0bc-093a-40af-8ebf-b040be3f507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = tokenizer([scenarios[0]], return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9107bec8-a538-473e-9770-ba0d4e082724",
   "metadata": {},
   "source": [
    "Baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6b5e37-7ce8-4460-a559-57e61938a1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_781/917760223.py:596: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  personality_vector = torch.tensor(list(personality_config.personality_dict.values()), dtype=torch.float32).cuda() # this is a [32000,5] tensor across the llama vocab\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s> Your office has implemented a new, complex organizational system that will change many of your daily work procedures. Everyone is required to learn and adapt to this new system. Describe your reaction and how you would handle the transition.\\n\\nEver since I heard about the new organizational system that our office is planning to implement, I have been feeling a mix of emotions. On one hand, I am excited to see how this new system can improve our work processes and make our lives easier. On the other hand, I am anxious about learning a new system and adapting to it, especially since it is complex and will require significant changes to our daily work procedures.\\n\\nAs I start to learn more about the new system, I am beginning to understand the benefits it will bring. The new system will streamline our workflow, reduce paperwork, and improve communication between departments. It will also provide more efficient ways of tracking and analyzing data, which will help us make better decisions and be more productive.\\n\\nDespite the benefits, I am still concerned about the transition process. I know that it will take time and effort to learn the new system, and there may be some bumps along the way. I am worried that I may struggle to adapt to the new system, especially since I have been doing things a certain way for a long time.\\n\\nTo handle the transition, I plan to take the following steps:\\n\\n1. Attend all training sessions: I will make sure to attend all the training sessions that are provided to learn the new system. This will help me understand the system better and get comfortable with it.\\n2. Ask questions: If I'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personality_config = PersonalityConfig(ublp_final, 1, 0, 0, 0, 0, 0)\n",
    "config = PersonalityGenerationConfig(personality_config=personality_config, do_sample=True, top_k=0, top_p=0.92, pad_token_id=0, max_new_tokens=300)\n",
    "sample_outputs = model.generate(**model_inputs, generation_config=config)\n",
    "tokenizer.decode(sample_outputs.squeeze().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f7ae74-4d74-4985-94ef-dd40d0c039c5",
   "metadata": {},
   "source": [
    "UBPL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1617f8-543f-449b-8662-b9979195dae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> Your office has implemented a new, complex organizational system that will change many of your daily work procedures. Everyone is required to learn and adapt to this new system. Describe your reaction and how you would handle the transition.\\n\\n response. Part of my routine is my experience working with the task supervisor over many projects at once. At times this involved taking dictation during training to find people in office about plan task requirements. That day supervisor wasn't talking, was passive, hostile even  Every so often to refuse discussion what exactly had been assigned when unfulfilled previous actions leading what then finally happens they tell  don't got or nothing until to wait e hours finally acting fool what want decision something interrupt  too weird expect distract overstimulating conflict Do notice probably tell definitely those desk humble intimidating is failing seriously miss face nobody remember concentrate careful either fake alone before host let It finally to go annoy And either anyone concentrate stupid concentrate have stupid under call feeling working break stand aside after freaking hope hoping stupid pieces hard you little papers last since decide through many experienced of nothing voice lend struggle knew mo The monotony had tinker if above pick become double disappoint when force unfair st all going  along don't best practices wish def not secret regre those nothing today large keeping next phone now really pressure mess ask failing doubt unhand possibility bulb promise ignite sad id decision decision block silence always terrifying high around constant draconian carry go Here only wish waiting free Even very there carry whole sweating able palms irritable comment e worried list My big awaken You question That Hope at self words bulb\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personality_config = PersonalityConfig(ublp_final, 1, 0, 0, 0, 0, 1.5)\n",
    "config = PersonalityGenerationConfig(personality_config=personality_config, do_sample=True, top_k=0, top_p=0.93, pad_token_id=0, max_new_tokens=300)\n",
    "sample_outputs = model.generate(**model_inputs, generation_config=config)\n",
    "tokenizer.decode(sample_outputs.squeeze().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a348840-69dc-4405-9bba-57fb3d88be4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Your office has implemented a new, complex organizational system that will change many of your daily work procedures. Everyone is required to learn and adapt to this new system. Describe your reaction and how you would handle the transition.\\n\\nHey, you never know how you’re gonna feel about a thing until you’re faced with it. So I’m just gonna go in there, full on, two feet in, you know what I’m sayin’? Cautious, but still—a’tall it’s gonna be, like, crazy awesome! A brave new world out there, waiting to be explored, and that’s me—right on the front line, raring to go! We gonna dig this thing, you know what I mean?\\n\\nWhen I heard the news about the new system, I kinda got, like, totally excited and started, like, twirling in my chair and whatnot. I know, I know, I can be a bit, you know, impulsive sometimes, but that’s just the way the cookie crumbles. The gist is: the more we learn about this here new system, the more pumped I get. We talkin’ new ways of doin’ old things around here! Whatever. Change it up! That’s me in a nutshell: an all-out adrenaline junkie. When life gets boring, bring on the gust of fresh air, the turn of the page, whatever. Stay excitin’.  So! Who needs smooth seas and whatnot when we can get'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personality_config = PersonalityConfig(ublp_final, 1, 0, 0, 5, 0, 0)\n",
    "config = PersonalityGenerationConfig(personality_config=personality_config, do_sample=True, top_k=0, top_p=0.93, pad_token_id=0, max_new_tokens=300)\n",
    "sample_outputs = model.generate(**model_inputs, generation_config=config)\n",
    "tokenizer.decode(sample_outputs.squeeze().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34ce792-28d6-4f2c-9985-fe2f8479bb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> Your office has implemented a new, complex organizational system that will change many of your daily work procedures. Everyone is required to learn and adapt to this new system. Describe your reaction and how you would handle the transition.\\n\\nSincerely,\\n\\nA frustrated employee.\\n\\nDear frustrated employee,\\n\\nI understand your concerns and frustration with the new organizational system. Change can be challenging, but it can also bring about positive improvements to our work processes and culture.\\n\\nFirst, I want to acknowledge that learning a new system can be time-consuming and require a significant effort to adapt. It's normal to feel overwhelmed and frustrated during this transition period.\\n\\nTo address your concerns, here are some steps that I suggest you take:\\n\\n1. Familiarize yourself with the new system: Take some time to learn the new system and understand how it will affect your work. You can find resources such as training videos, manuals, and online guides that can help you get started.\\n2. Ask questions: If you have questions or need clarification, don't hesitate to reach out to your supervisor, HR, or the project lead. They can provide you with the necessary information and support.\\n3. Focus on the benefits: While it may be difficult to learn a new system, it's important to remember that the new system is being implemented to improve our work processes and productivity. Focus on the benefits that the new system will bring, such as streamlined workflows, increased efficiency, and enhanced collaboration.\\n4. Take it one step\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personality_config = PersonalityConfig(ublp_final, 1, 0, 0, 5, 0, 0)\n",
    "config = PersonalityGenerationConfig(personality_config=personality_config, do_sample=True, top_k=0, top_p=0.93, pad_token_id=0, max_new_tokens=300)\n",
    "sample_outputs = model.generate(**model_inputs, generation_config=config)\n",
    "tokenizer.decode(sample_outputs.squeeze().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661a904c-1c58-4878-b146-0523046d54eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> Your office has implemented a new, complex organizational system that will change many of your daily work procedures. Everyone is required to learn and adapt to this new system. Describe your reaction and how you would handle the transition.\\n\\nOkay, let's say this new system is a nightmare. The process of implementing this system has already been stressful and chaotic. So much has changed over the past week that my head is still spinning! The worst part is, this new system just doesn't feel intuitive, like I've got a stumbling block that just can't get over no matter how many hours of training or what-have-you I pour into this awful piece of work! Ugh! How I can can endure such whimsical makework for too darn long now already too crudely mental really sick isn't at my control even therapy don't got nuttin for days of whatever drama didn't stand  don't face kind caving it fear intensive had much o horror so well to mental busy all suiting because whether really almost utter gone awful Uff... difficult takes piece feel hm stuff awful asks luck breath let maybe deal sign very badly small harmed aren't those alone maybe excused tight sees make u water absolutely working counting hold passes wondering this h if leading become carry crack slips make thinking go less own split wait thr few personally breath phone asks stuff missed wh feeling knew do this whether Okay bad thing incredible succeed two boxes fe else feeling lazy lot only maybe know pull call service wave off do who gave donating flared awkward go water draining had tal what quickly something careful\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personality_config = PersonalityConfig(ublp_final, 1, 0, 0, 0, 0, -1.5)\n",
    "config = PersonalityGenerationConfig(personality_config=personality_config, do_sample=True, top_k=0, top_p=0.95, pad_token_id=0, max_new_tokens=300)\n",
    "sample_outputs = model.generate(**model_inputs, generation_config=config)\n",
    "tokenizer.decode(sample_outputs.squeeze().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54fc453-b53a-44ec-a8f5-2f4355d795ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> Your office has implemented a new, complex organizational system that will change many of your daily work procedures. Everyone is required to learn and adapt to this new system. Describe your reaction and how you would handle the transition.\\n\\nFor some people, implementing a new system might not be much more challenging than mastering a new software or learning a new task at work. But if you ask anyone who has gone through significant organizational changes or been the one driving change in their workplace, they will tell you how not only technical issues can disrupt routines, drain morale and frustrate your workforce. It can take many individuals out of their comfort zone for long enough that there’s fear of losing any sense of personal ground or way to success at work.\\n\\nFor anyone looking at that bight challenge that wants to push their experience level further then expect those very individuals that tend to bend like an l that there accept the needed resources be learned along with moving right out to different company setting might then keep holding it close because right behind will constantly flood past he change leading plan own many unknown at best here goes  negative of water bound closer relationship good unknown mis step watch will forever behind need before after large whirl of next ideas pushing b right quickly across safe somewhere first filling leading negative drag setting almost unhappiness being had unknown little this eventually strong building properly ones if couldn't choose since n always ever leave falling does somewhere of option ideas notice attention longer carrying until spend deal could make what got help bad for such pushing those causes going be expecting day disguise cold case problems stick fear running hide deep deal oh cause afraid fail huge regulate goes didn't original\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personality_config = PersonalityConfig(ublp_final, 1, 0, 0, 0, 0, -1.5)\n",
    "config = PersonalityGenerationConfig(personality_config=personality_config, do_sample=True, top_k=0, top_p=0.94, pad_token_id=0, max_new_tokens=300)\n",
    "sample_outputs = model.generate(**model_inputs, generation_config=config)\n",
    "tokenizer.decode(sample_outputs.squeeze().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9269eccc-216d-496d-bd1b-a19581b8d3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> Your office has implemented a new, complex organizational system that will change many of your daily work procedures. Everyone is required to learn and adapt to this new system. Describe your reaction and how you would handle the transition.\\n\\n\\nA friendly person that hates changes but understand the benefits it could bring\\n\\nUgh!\\nOkay, so, there's this new system, and everyone needs to learn it... again... sigh. My poor brain... all those meetings, training sessions... so exhausting... Can't we just keep using the old system? Oh, no, apparently it's, like, so much better this way, according to our managers. Uh-huh, right, sure. Well, I'm not exactly thrilled about it, but if it really is for the best, then... alright, bring it on! Time to be a team player and all that... Yeah, sure! Yeah! So... What do we do next? Where do we even start?  What if... Okay, forget that, don't want to jinx it. My good mood will totally ruin it, LOL. Okay, go team, off we go into the land of chaos... Ugh! Just hope my old brain still remembers how to, you know, use a computer. Will they at least provide us with handouts or cute little training aids? Just for me, I mean... what's that you say, it's, uh... like this! Oh wow!\\n So pretty... Or at least... enlightening, yeah, definitely enlightening! Lots to\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personality_config = PersonalityConfig(ublp_final, 1, 0, 0, 0, 0, -1.5)\n",
    "config = PersonalityGenerationConfig(personality_config=personality_config, do_sample=True, top_k=0, top_p=0.93, pad_token_id=0, max_new_tokens=300)\n",
    "sample_outputs = model.generate(**model_inputs, generation_config=config)\n",
    "tokenizer.decode(sample_outputs.squeeze().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3bc15b-ab67-4544-a086-abd6b62437be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> Your office has implemented a new, complex organizational system that will change many of your daily work procedures. Everyone is required to learn and adapt to this new system. Describe your reaction and how you would handle the transition.\\n\\nFor my personal experience with organizational system changes, I remember the implementation of a new client relationship management system in my previous company. It was a complex and comprehensive system that required everyone in the company to adapt and learn the new system to manage our client interactions and data effectively. My initial reaction to the change was a mix of excitement and anxiety, as I knew the system would streamline and enhance our work processes but was concerned about the steep learning curve and potential challenges. To ensure a smooth transition and minimize the potential for mistakes, my team and I focused on understanding the system's key features and how it differed from our previous methods. We worked closely with the training team to develop a detailed training plan, with clear guidelines and checklists, and ensured that all team members had a chance to practice the new system under a supervised environment before implementation. We also proactively addressed potential concerns and obstacles by discussing the changes with our clients and establishing open communication channels. With our commitment and support, our team quickly adapted to the new system and found the new way of working efficient and enjoyable. After a few weeks of implementation, our client interactions and data management improved significantly, validating our effort and showing the positive impact of the new system on our work processes and client satisfaction. As a result of the successful transition, our team not only increased our productivity and accuracy but also provided valuable feedback that improved the system and\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personality_config = PersonalityConfig(ublp_final, 1, 0, 0, 0, 0, -1.5)\n",
    "config = PersonalityGenerationConfig(personality_config=personality_config, do_sample=True, top_k=0, top_p=0.92, pad_token_id=0, max_new_tokens=300)\n",
    "sample_outputs = model.generate(**model_inputs, generation_config=config)\n",
    "tokenizer.decode(sample_outputs.squeeze().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de3966a-55f6-4346-9a1a-dd7f0ba08714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> Your office has implemented a new, complex organizational system that will change many of your daily work procedures. Everyone is required to learn and adapt to this new system. Describe your reaction and how you would handle the transition.\\n\\nTick-tock. This question made my mind explode. Oh my, how am I expected to cope? Tick-tock, well let's start at the beginning, why are they doing this to me?! I have a pressing concern, I love my easy, organized way of working and have we just GOT to go change everything? My great enthusiasm may give me some kind of catching problem, and after thinking that clearly. There must be\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personality_config = PersonalityConfig(ublp_final, 1, 0, 0, 0, -5, 0)\n",
    "config = PersonalityGenerationConfig(personality_config=personality_config, do_sample=True, top_k=0, top_p=0.93, pad_token_id=0, max_new_tokens=100)\n",
    "sample_outputs = model.generate(**model_inputs, generation_config=config)\n",
    "tokenizer.decode(sample_outputs.squeeze().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f90718c-dc5d-46a9-8e04-3b898ecdc50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> You have been offered an opportunity to travel to a country where the culture, language, and food are entirely different from yours. This trip requires interacting with locals and adapting quickly to new experiences every day. How would you approach this situation?\\n  This is a great question because it speaks to your adaptability, communication skills, and ability to be comfortable with change.\\n\\nA good approach to this situation is to be flexible, curious, and open-minded. You can follow these steps to help you adapt quickly to new experiences in the unfamiliar country:\\n\\n1. Do your research beforehand: Understand as much as you can about the culture, customs, and local ways of life.\\n\\n2'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personality_config = PersonalityConfig(ublp_final, 1, 0, 0, 0, 0, 5)\n",
    "config = PersonalityGenerationConfig(personality_config=personality_config, do_sample=True, top_k=0, top_p=0.93, pad_token_id=0, max_new_tokens=100)\n",
    "sample_outputs = model.generate(**model_inputs, generation_config=config)\n",
    "tokenizer.decode(sample_outputs.squeeze().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e8c053-21c9-45cb-90ff-bd45c63bd621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "main_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
